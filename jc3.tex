% Chapter 4, Section 1 _Linear Algebra_ Jim Hefferon
%  http://joshua.smcvt.edu/linalg.html
%  2001-Jun-12
\section{Nilpotence}
The goal of this chapter is to show that every square matrix is similar to one
that is a sum of two kinds of simple matrices.
The prior section
focused on the first simple kind, diagonal matrices.
We now consider the other.









\subsectionoptional{Self-Composition}\index{self composition!of maps}\index{map!self composition}\index{transformation!composed with itself}\index{composition!self}
% \noindent\textit{This subsection is optional, although it is necessary
% for later material in this section and in the next one.}

Because a linear transformation $\map{t}{V}{V}$ has the same domain as
codomain, we can
find the composition of $t$ with itself 
\( t^2=\composed{t}{t} \), 
and \( t^3=\composed{t}{\composed{t}{t}} \), etc.\appendrefs{function interation}\spacefactor=1000 %
\begin{center}
  \includegraphics{ch5.1}
\end{center}
Note that the superscript
power notation $t^j$ for iterates of the transformations 
dovetails with 
the notation that we've used for their square matrix representations
because if $\rep{t}{B,B}=T$ then \( \rep{t^j}{B,B}=T^j \).


\begin{example} \label{ex:DerivIter}
For the derivative map \( \map{d/dx}{\polyspace_3}{\polyspace_3} \)
given by 
\begin{equation*}
  a+bx+cx^2+dx^3\xmapsunder{d/dx} b+2cx+3dx^2
\end{equation*}
the second power is the second derivative
\begin{equation*}
  a+bx+cx^2+dx^3\xmapsunder{d^2/dx^2} 2c+6dx 
\end{equation*}
the third power is the third derivative
\begin{equation*}
  a+bx+cx^2+dx^3\xmapsunder{d^3/dx^3} 6d 
\end{equation*}
and any higher power is the zero map.
\end{example}

\begin{example}
This transformation of the space of $\nbyn{2}$ matrices
\begin{equation*}
  \begin{mat}
    a  &b  \\
    c  &d
  \end{mat}
  \mapsunder{t}
  \begin{mat}
    b  &a  \\
    d  &0
  \end{mat}
\end{equation*}
has this second power
\begin{equation*}
  \begin{mat}
    a  &b  \\
    c  &d
  \end{mat}
  \mapsunder{t^2}
  \begin{mat}
    a  &b  \\
    0  &0
  \end{mat}
\end{equation*}
and this third power.
\begin{equation*}
  \begin{mat}
    a  &b  \\
    c  &d
  \end{mat}
  \mapsunder{t^3}
  \begin{mat}
    b  &a  \\
    0  &0
  \end{mat}
\end{equation*}
After that, $t^4=t^2$ and $t^5=t^3$, etc.
\end{example}

These examples suggest that after some number of iterations
the map settles down.

\begin{lemma}  \label{le:RangeAndNullChains}
For any transformation \( \map{t}{V}{V} \), the rangespaces of the powers
form a descending chain
\begin{equation*}
  V\supseteq \rangespace{t}\supseteq\rangespace{t^2}\supseteq\cdots
\end{equation*}
and the nullspaces form an ascending chain.
\begin{equation*}
  \set{\vec{0}\,}\subseteq\nullspace{t}\subseteq\nullspace{t^2}\subseteq\cdots
\end{equation*}
Further, there is a \( k \) such that
for powers less than $k$ the subsets are proper
so that if $j<k$ then $\rangespace{t^j}\supset\rangespace{t^{j+1}}$
and 
$\nullspace{t^j}\subset\nullspace{t^{j+1}}$
while for higher powers the sets are equal,
that is, if $j\geq k$ then $\rangespace{t^j}=\rangespace{t^{j+1}}$
and 
$\nullspace{t^j}=\nullspace{t^{j+1}}$).  
\end{lemma}

\begin{proof}
First recall that for any map the dimension of its rangespace
plus the dimension of its nullspace equals
the dimension of its domain,
So if the dimensions of the rangespaces shrink then the 
dimensions of the nullspaces must grow.
We will do the rangespace half here and leave the rest for
\nearbyexercise{exer:RangeAndNullChains}.

First we show that 
that the rangespaces form a chain.
If $\vec{w}\in\rangespace{t^{j+1}}$, so that
$\vec{w}=t^{j+1}(\vec{v})$, 
then $\vec{w}=t^{j}(\,t(\vec{v})\,)$.
Thus $\vec{w}\in\rangespace{t^{j}}$.

Next we verify the ``further'' property:
while the subsets in the chain of rangespaces may be proper 
for a while, from some power $k$ onward the rangespaces are equal. 
We first show that if any pair of adjacent rangespaces in the
chain are equal \( \rangespace{t^{k}}=\rangespace{t^{k+1}} \)
then all subsequent ones are also equal
\( \rangespace{t^{k+1}}=\rangespace{t^{k+2}} \), etc.
This holds because
\( \map{t}{\rangespace{t^{k+1}}}{\rangespace{t^{k+2}}} \)
is the same map, with the same domain, as
\( \map{t}{\rangespace{t^{k}}}{\rangespace{t^{k+1}}} \) and
it therefore has the same range
\( \rangespace{t^{k+1}}=\rangespace{t^{k+2}} \)
(it holds for all higher powers by induction).
So if the chain of rangespaces ever stops strictly decreasing then
from that point onward it is stable.

We end by showing that the chain must eventually stop decreasing. 
Each rangespace is a subspace of the one before it.
For it to be a proper subspace it must be of strictly lower dimension
(see \nearbyexercise{exer:PropSubspStrictLowerDimen}).
These spaces are finite-dimensional and so the chain can fall for only
finitely-many steps,
that is, the power $k$ is at most the dimension of $V$.
\end{proof}

\begin{example}
The derivative map $a+bx+cx^2+dx^3\xmapsunder{d/dx} b+2cx+3dx^2$
of \nearbyexample{ex:DerivIter} has this chain of rangespaces
\begin{equation*}
  \polyspace_3\supset\polyspace_2\supset\polyspace_1
    \supset\polyspace_0\supset\set{\zero\,}=\set{\zero\,}=\cdots
\end{equation*}
and this chain of nullspaces.
\begin{equation*}
  \set{\zero\,}\subset\polyspace_0\subset\polyspace_1\subset\polyspace_2
    \subset\polyspace_3=\polyspace_3=\cdots
\end{equation*}
\end{example}

\begin{example}
The transformation \( \map{\pi}{\C^3}{\C^3} \) projecting onto the
first two coordinates
\begin{equation*}
   \colvec{c_1 \\ c_2 \\ c_3}
     \mapsunder{\pi}
   \colvec{c_1 \\ c_2 \\ 0}
\end{equation*}
has \( \C^3\supset\rangespace{\pi}=\rangespace{\pi^2}=\cdots \)
and \( \set{\zero\,}\subset\nullspace{\pi}=\nullspace{\pi^2}=\cdots\, \).
\end{example}

\begin{example} \label{exam:PolyRankFalls}
Let \( \map{t}{\polyspace_2}{\polyspace_2} \) be the map
\( c_0+c_1x+c_2x^2 \mapsto 2c_0+c_2x. \)
As the lemma describes, on
iteration the rangespace shrinks
\begin{equation*}
  \rangespace{t^0}=\polyspace_2
    \quad
  \rangespace{t}=\set{a+bx\suchthat a,b\in\C}
    \quad
  \rangespace{t^2}=\set{a\suchthat a\in\C}
\end{equation*}
and then stabilizes $\rangespace{t^2}=\rangespace{t^3}=\cdots$,
while the nullspace grows
\begin{equation*}
  \nullspace{t^0}=\set{0}
    \quad
  \nullspace{t}=\set{cx\suchthat c\in\C}
    \quad
  \nullspace{t^2}=\set{cx+d\suchthat c,d\in\C}
\end{equation*}
and then stabilizes $\nullspace{t^2}=\nullspace{t^3}=\cdots$.
\end{example}

This graph illustrates \nearbylemma{le:RangeAndNullChains}.
The horizontal axis gives the power~$j$ of a transformation.
The vertical axis gives
the dimension of the rangespace of $t^j$
as the distance above zero\Dash and thus also shows the dimension of the 
nullspace as the distance below the gray horizontal line, 
because the two add to the dimension $n$ of the domain.
\begin{center}
  % \includegraphics{ch5.2}
  \includegraphics{ch5.8}
\end{center}
As sketched, on iteration 
the rank falls and with it the nullity grows 
until the two reach a steady state.
This state must be reached by the $n$-th iterate.
The steady state's distance above zero is the dimension of the 
generalized rangespace
and its distance below $n$ is the dimension of
the generalized nullspace.

\begin{definition}
Let \( t \) be a transformation on an \( n \)-dimensional space.
The \definend{generalized rangespace}\index{generalized rangespace}%
\index{rangespace!generalized}
(or the \definend{closure of the rangespace\/}\index{closure!of rangespace}%
\index{rangespace!closure of})
is $\genrangespace{t}=\rangespace{t^n}$
The \definend{generalized nullspace}\index{generalized nullspace}%
\index{nullspace!generalized}
(or the \definend{closure of the nullspace\/}\index{closure!of nullspace}%
\index{nullspace!closure of})
is $\gennullspace{t}=\nullspace{t^n}$.
\end{definition}

\begin{exercises}
  \item 
    Give the chains of rangespaces and nullspaces for the zero and
    identity transformations.
    \begin{answer}
      For the zero transformation,
      no matter what the space, the chain of rangespaces 
      is \( V\supset\set{\vec{0}}=\set{\vec{0}}=\cdots\, \)
      and the chain of nullspaces is \( \set{\vec{0}}\subset V=V=\cdots\, \).
      For the identity transformation the chains are
      \( V=V=V=\cdots \) and
      \( \set{\vec{0}}=\set{\vec{0}}=\cdots\, \). 
    \end{answer}
  \item 
     For each map, 
     give the chain of rangespaces and the chain of nullspaces,
     and the generalized rangespace and the 
     generalized nullspace.
     \begin{exparts}
       \partsitem $\map{t_0}{\polyspace_2}{\polyspace_2}$, 
         $a+bx+cx^2\mapsto b+cx^2$ 
       \partsitem $\map{t_1}{\Re^2}{\Re^2}$,
         \begin{equation*}
           \colvec{a \\ b}\mapsto\colvec{0 \\ a}
         \end{equation*}
       \partsitem $\map{t_2}{\polyspace_2}{\polyspace_2}$, 
         $a+bx+cx^2\mapsto b+cx+ax^2$
       \partsitem $\map{t_3}{\Re^3}{\Re^3}$,
         \begin{equation*}
           \colvec{a \\ b \\ c}\mapsto\colvec{a \\ a \\ b}
         \end{equation*}
     \end{exparts}
     \begin{answer}
       \begin{exparts}
         \partsitem Iterating $t_0$ twice  
           $a+bx+cx^2\mapsto b+cx^2\mapsto cx^2$
           gives 
           \begin{equation*}
             a+bx+cx^2\mapsunder{t_0^2}cx^2
           \end{equation*}
           and any higher power is the same map.
           Thus, while $\rangespace{t_0}$ is the space of 
           quadratic polynomials
           with no linear term $\set{p+rx^2\suchthat p,r\in \C}$,
           and
           $\rangespace{t_0^2}$ is the space of purely-quadratic polynomials
           $\set{rx^2\suchthat r\in \C}$, 
           this is where the chain stabilizes
           $\genrangespace{t_0}=\set{rx^2\suchthat n\in \C}$. 
           As for nullspaces, 
           $\nullspace{t_0}$ is the space of purely-linear quadratic 
           polynomials $\set{qx\suchthat q\in \C}$, and
           $\nullspace{t_0^2}$ is the space of quadratic polynomials
           with no $x^2$ term $\set{p+qx\suchthat p,q\in \C}$, and
           this is the end $\gennullspace{t_0}=\nullspace{t_0^2}$. 
         \partsitem The second power
           \begin{equation*}
             \colvec{a \\ b}
              \mapsunder{t_1}\colvec{0 \\ a}
              \mapsunder{t_1}\colvec{0 \\ 0}
           \end{equation*}
           is the zero map.
           Consequently, the chain of rangespaces
           \begin{equation*}
             \Re^2
               \supset\set{\colvec{0 \\ p}\suchthat p\in\C}
               \supset\set{\zero\,}
               =\cdots
           \end{equation*}
           and the chain of nullspaces 
           \begin{equation*}
             \set{\zero\,}
               \subset\set{\colvec{q \\ 0}\suchthat q\in\C}
               \subset\Re^2
               =\cdots
           \end{equation*}
           each has length two.
           The generalized rangespace is the trivial subspace and the
           generalized nullspace is the entire space.
         \partsitem Iterates of this map cycle around
           \begin{equation*}
             a+bx+cx^2
               \mapsunder{t_2} b+cx+ax^2            
               \mapsunder{t_2} c+ax+bx^2            
               \mapsunder{t_2} a+bx+cx^2
               \;\cdots            
           \end{equation*}
           and the chains of rangespaces and nullspaces are trivial. 
           \begin{equation*}
             \polyspace_2=\polyspace_2=\cdots
              \qquad
              \set{\zero\,}=\set{\zero\,}=\cdots  
           \end{equation*}
           Thus, obviously,
           generalized spaces are $\genrangespace{t_2}=\polyspace_2$
           and $\gennullspace{t_2}=\set{\zero\,}$.
         \partsitem We have 
           \begin{equation*}
             \colvec{a \\ b \\ c}
                \mapsto\colvec{a \\ a \\ b}
                \mapsto\colvec{a \\ a \\ a}
                \mapsto\colvec{a \\ a \\ a}
                \mapsto\cdots
           \end{equation*}
           and so the chain of rangespaces 
           \begin{equation*}
             \Re^3
               \supset\set{\colvec{p \\ p \\ r}\suchthat p,r\in\C}
               \supset\set{\colvec{p \\ p \\ p}\suchthat p\in\C}
               =\cdots
           \end{equation*}
           and the chain of nullspaces
           \begin{equation*}
             \set{\zero\,}
                \subset\set{\colvec{0 \\ 0 \\ r}\suchthat r\in \C}
                \subset\set{\colvec{0 \\ q \\ r}\suchthat q,r\in \C}
                =\cdots
           \end{equation*}
           each has length two.
           The generalized spaces are the final ones shown above in each chain.
      \end{exparts}
     \end{answer}
  \item 
    Prove that function composition is associative
    \( \composed{(\composed{t}{t})}{t}=\composed{t}{(\composed{t}{t})} \)
    and so we can write $t^3$ without specifying a grouping.
    \begin{answer}
      Each maps \( x\mapsto t(t(t(x))) \). 
    \end{answer}
  \item \label{exer:PropSubspStrictLowerDimen}
    Check that a subspace must be of dimension less than or equal to the 
    dimension of its superspace.
    Check that if the subspace is proper (the subspace does not equal the
    superspace) then the dimension is strictly less.
    \textit{(This is used in the proof of
             \nearbylemma{le:RangeAndNullChains}.)}
    \begin{answer}
      Recall that if $W$ is a subspace of $V$ then any basis $B_W$ for $W$
      can be 
      enlarged to make a basis $B_V$ for $V$.
      From this the first sentence is immediate.
      The second sentence is also not hard:~$W$ is the span of $B_W$ and
      if $W$ is a proper subspace then $V$ is not the span of $B_W$, and
      so $B_V$ must have at least one vector more than does $B_W$.     
    \end{answer}
  \item 
    Prove that the generalized rangespace $\genrangespace{t}$ is the
    entire space, and the generalized nullspace $\gennullspace{t}$ is trivial,
    if the transformation $t$ is nonsingular.
    Is this `only if' also?
    \begin{answer}
      It is both `if' and `only if'.
      A linear map is nonsingular
      if and only if it preserves dimension, that is, if the dimension of 
      its range equals the dimension of its domain.
      With a transformation $\map{t}{V}{V}$ that means that 
      the map is nonsingular if and only if it is onto:
      $\rangespace{t}=V$ (and thus $\rangespace{t^2}=V$, etc).
    \end{answer}
  \item \label{exer:RangeAndNullChains} 
    Verify the nullspace half of \nearbylemma{le:RangeAndNullChains}.
    \begin{answer}
      The nullspaces form chains because
      because if $\vec{v}\in\nullspace{t^j}$ then $t^j(\vec{v})=\zero$
      and $t^{j+1}(\vec{v})=t(\,t^j(\vec{v})\,)=t(\zero)=\zero$ and
      so $\vec{v}\in\nullspace{t^{j+1}}$.

      Now, 
      the ``further'' property for nullspaces follows from that fact
      that it holds for rangespaces, along with the prior exercise.
      Because the dimension of $\rangespace{t^j}$ plus the dimension of
      $\nullspace{t^j}$ equals the dimension~$n$ of the starting space~$V$,
      when the dimensions of the rangespaces stop decreasing, so do the
      dimensions of the nullspaces.
      The prior exercise shows that from this point~$k$ on, 
      the containments in the chain are not proper\Dash the nullspaces 
      are equal. 
    \end{answer}
\item
    Give an example of a transformation on a three
    dimensional space whose range has dimension two.
    What is its nullspace?
    Iterate your example until the rangespace and nullspace stabilize.
    \begin{answer}
      (Of course, many examples are correct, but here is one.) 
      An example is the shift operator on triples of reals
      \( (x,y,z)\mapsto (0,x,y) \).
      The nullspace is all triples that start with two zeros.
      The map stabilizes after three iterations.
     \end{answer}
  \item 
      Show that the rangespace and nullspace of a linear transformation
      need not be disjoint.
      Are they ever disjoint?
      \begin{answer}
        The differentiation operator
        \( \map{d/dx}{\polyspace_1}{\polyspace_1} \) has the same
        rangespace as nullspace.
        For an example of where they are disjoint\Dash
        except for the zero vector\Dash consider an identity map,
        or any nonsingular map. 
      \end{answer}
\end{exercises}

















\subsectionoptional{Strings}
\index{nilpotent|(}
\noindent\textit{This subsection is optional, and requires material from the 
    optional Direct Sum subsection.}

The prior subsection shows that as \( j \) increases,
the dimensions of the $\rangespace{t^j}$'s fall while
the dimensions of the $\nullspace{t^j}$'s rise, 
in such a way that this rank and nullity split the dimension of $V$.
Can we say more;
do the two split a basis\Dash is
\( V=\rangespace{t^j}\directsum\nullspace{t^j} \)?

The answer is yes for the smallest power $j=0$ since
\( V=\rangespace{t^0}\directsum\nullspace{t^0}=V\directsum\set{\zero} \).
The answer is also yes at the other extreme.

\begin{lemma} \label{GenRngNullDirSumToSp}
Where \( \map{t}{V}{V} \) is a linear transformation, 
the space is the direct sum 
\( V=\genrangespace{t}\directsum\gennullspace{t} \).
That is, both \( \dim(V)=\dim(\genrangespace{t})+\dim(\gennullspace{t}) \) and
\( \genrangespace{t}\intersection\gennullspace{t}=\set{\zero\,} \).
\end{lemma}

\begin{proof}
We will verify the second sentence, which is equivalent to the first.
The first clause, that the dimension $n$ of the domain of $t^n$ equals
the rank of $t^n$ plus the nullity of $t^n$, holds for any transformation and
so we need only verify the second clause.

Assume that
\( \vec{v}\in\genrangespace{t}\intersection\gennullspace{t}
              =\rangespace{t^n}\intersection\nullspace{t^n} \),
to prove that $\vec{v}$ is \( \zero \).
Because \( \vec{v} \) is in the nullspace, \( t^n(\vec{v})=\zero \).
On the other hand, because \( \rangespace{t^n}=\rangespace{t^{n+1}} \),
the map \( \map{t}{\genrangespace{t}}{\genrangespace{t}} \) is
a dimension-preserving homomorphism and therefore is one-to-one.
A composition of one-to-one maps is one-to-one, and so
\( \map{t^n}{\genrangespace{t}}{\genrangespace{t}} \) is one-to-one.
But now\Dash because only \( \zero \) is sent by a one-to-one linear map to
\( \zero \)\Dash the fact that \( t^n(\vec{v})=\zero \) implies that
\( \vec{v}=\zero \).
\end{proof}

\begin{note} \label{note:RestONeToOne}
Technically we should distinguish the map $\map{t}{V}{V}$ from
the map \( \map{t}{\genrangespace{t}}{\genrangespace{t}} \) 
because the domains or codomains might differ.
The second one is said to be the 
\definend{restriction}\appendrefs{map restrictions}\spacefactor=1000 %
of $t$ to 
$\rangespace{t^k}$. 
We shall use later a point from that proof about the restriction map, 
namely that it is one-to-one.
\end{note}

In contrast to the $j=0$ and~$j=n$ cases, for intermediate powers 
the space $V$ might not be the direct sum of
$\rangespace{t^j}$ and $\nullspace{t^j}$.
The next example shows that the two can have a nontrivial intersection.

\begin{example}   \label{FirstNilMap}
Consider the transformation of \( \C^2 \)
defined by this action on the elements of the standard basis.
\begin{equation*}
  \colvec[r]{1 \\ 0}
    \mapsunder{n}
    \colvec[r]{0 \\ 1}
  \quad
  \colvec[r]{0 \\ 1}
    \mapsunder{n}
    \colvec[r]{0 \\ 0}
  \qquad
  N=\rep{n}{\stdbasis_2,\stdbasis_2}=\begin{mat}[r]
    0  &0  \\
    1  &0
  \end{mat}
\end{equation*}
The vector 
\begin{equation*}
  \vec{e}_2=\colvec[r]{0 \\ 1}
\end{equation*}
is in both the rangespace and nullspace.
Another way to depict this map's action is with a 
\definend{string}.\index{string!of basis vectors}
\begin{equation*}
  \begin{strings}{ccccc}
     \vec{e}_1 &\mapsto &\vec{e}_2 &\mapsto &\zero
  \end{strings}
\end{equation*}
\end{example}

\begin{example}  \label{NilIndexFourOnCFour}
A map \( \map{\hat{n}}{\C^4}{\C^4} \)
whose action on \( \stdbasis_4 \) is given by
the string
\begin{equation*}
  \begin{strings}{ccccccccc}
     \vec{e}_1 &\mapsto &\vec{e}_2
          &\mapsto &\vec{e}_3
          &\mapsto &\vec{e}_4
          &\mapsto &\zero
  \end{strings}
\end{equation*}
has
\( \rangespace{\hat{n}}\intersection\nullspace{\hat{n}} \) equal to the 
span \( \spanof{\set{\vec{e}_4}} \),
has \( \rangespace{\hat{n}^2}\intersection\nullspace{\hat{n}^2}=
  \spanof{\set{\vec{e}_3,\vec{e}_4}} \),
and has \( \rangespace{\hat{n}^3}\intersection\nullspace{\hat{n}^3}=
    \spanof{\set{\vec{e}_4}} \).
The matrix representation  is all zeros except for
some subdiagonal ones.
\begin{equation*}
  \hat{N}=\rep{\hat{n}}{\stdbasis_4,\stdbasis_4}
  =\begin{mat}[r]
    0  &0  &0  &0 \\
    1  &0  &0  &0 \\
    0  &1  &0  &0 \\
    0  &0  &1  &0 \
  \end{mat}
\end{equation*}
\end{example}

\begin{example} \label{ThirdNilMap}
Transformations can act via more than one string.
A transformation \( t \) acting on a basis
\( B=\sequence{\vec{\beta}_1,\dots,\vec{\beta}_5} \) by
\begin{equation*}
   \begin{strings}{ccccccc}
    \vec{\beta}_1 &\mapsto &\vec{\beta}_2 &\mapsto &\vec{\beta}_3
        &\mapsto &\zero \\
    \vec{\beta}_4 &\mapsto &\vec{\beta}_5 &\mapsto &\zero
  \end{strings}
\end{equation*}
is represented by a matrix that is all zeros except for blocks
of subdiagonal ones
\begin{equation*}
  \rep{t}{B,B}=
  \begin{pmat}{rrr|rr}
     0  &0  &0  &0  &0  \\
     1  &0  &0  &0  &0  \\
     0  &1  &0  &0  &0  \\ \hline
     0  &0  &0  &0  &0  \\
     0  &0  &0  &1  &0
  \end{pmat}
\end{equation*}
(the lines just visually organize the blocks).
\end{example}

In those three examples all vectors are eventually transformed to
zero.

\begin{definition} \label{def:nilpotent} \index{nilpotent!definition}
A \definend{nilpotent} transformation\index{transformation!nilpotent}%
\index{nilpotent!transformation}
is one with a power that is the zero map.
A \definend{nilpotent matrix}\index{matrix!nilpotent}%
\index{nilpotent!matrix}
is one with a power that is the zero matrix.
In either case, the least such power is the \definend{index of nilpotency}.%
\index{nilpotentcy!index}\index{index!of nilpotency}
\end{definition}

\begin{example}
In \nearbyexample{FirstNilMap} the index of nilpotency is two.
In \nearbyexample{NilIndexFourOnCFour} it is four.
In \nearbyexample{ThirdNilMap} it is three.
\end{example}

\begin{example}
The differentiation map \( \map{d/dx}{\polyspace_2}{\polyspace_2} \)
is nilpotent of index three since the third derivative of any quadratic
polynomial is zero.
This map's action is described by the string
$x^2\mapsto 2x\mapsto 2\mapsto 0$
and taking the basis \( B=\sequence{x^2,2x,2} \)
gives this representation.
\begin{equation*}
  \rep{d/dx}{B,B}=
  \begin{mat}[r]
     0  &0  &0  \\
     1  &0  &0  \\
     0  &1  &0
  \end{mat}
\end{equation*}
\end{example}

Not all nilpotent matrices are all zeros except for blocks of
subdiagonal ones.

\begin{example} \label{ex:NilMatNotCanon}
With the matrix $\hat{N}$ from \nearbyexample{NilIndexFourOnCFour},
and this four-vector basis
\begin{equation*}
  D=\sequence{\colvec[r]{1 \\ 0 \\ 1 \\ 0},
              \colvec[r]{0 \\ 2 \\ 1 \\ 0},
              \colvec[r]{1 \\ 1 \\ 1 \\ 0},
              \colvec[r]{0 \\ 0 \\ 0 \\ 1}}
\end{equation*}
a change of basis operation 
produces this representation with respect to \( D,D \).
\begin{equation*}
  \begin{mat}[r]
    1  &0  &1 &0 \\
    0  &2  &1 &0 \\
    1  &1  &1 &0 \\
    0  &0  &0 &1
  \end{mat}
  \begin{mat}[r]
    0  &0  &0 &0 \\
    1  &0  &0 &0 \\
    0  &1  &0 &0 \\
    0  &0  &1 &0
  \end{mat}
  \begin{mat}[r]
    1  &0  &1 &0 \\
    0  &2  &1 &0 \\
    1  &1  &1 &0 \\
    0  &0  &0 &1
  \end{mat}^{-1}\!\!
  =
  \begin{mat}[r]
   -1  &0  &1   &0 \\
   -3  &-2 &5   &0 \\
   -2  &-1  &3  &0 \\
    2  &1   &-2 &0
  \end{mat}
\end{equation*}
The new matrix is nilpotent; it's fourth power 
is the zero matrix since
\begin{equation*}
   (P\hat{N}P^{-1})^4
   =P\hat{N}P^{-1}\cdot P\hat{N}P^{-1}\cdot P\hat{N}P^{-1}\cdot P\hat{N}P^{-1}
   =P\hat{N}^4P^{-1}
\end{equation*}
and \( \hat{N}^4 \) is the zero matrix.
\end{example}

The goal of this subsection is \nearbytheorem{th:NilMapHasStrBas},
which shows that the prior example is prototypical
in that every nilpotent matrix is similar to one that is all
zeros except for blocks of subdiagonal ones.

\begin{definition}
Let \( t \) be a nilpotent transformation on \( V \).
A \definend{\( t \)-string generated by}\index{string}
\( \vec{v}\in V \) is a sequence
\( \sequence{\vec{v},t(\vec{v}),\ldots,t^{k-1}(\vec{v})} \).
This sequence has \definend{length}~$k$.
A \definend{\( t \)-string basis}\index{basis!string}\index{string!basis}
is a basis that is a concatenation of \( t \)-strings.
\end{definition}

\begin{example}
In \nearbyexample{ThirdNilMap}, the $t$-strings
$\sequence{\vec{\beta}_1,\vec{\beta}_2,\vec{\beta}_3}$ and
$\sequence{\vec{\beta}_4,\vec{\beta}_5}$, of length three and two,
can be concatenated to make a basis for the domain of $t$.
\end{example}

\begin{lemma}  \label{le:LongestTowerIsIndex}
If a space has a \( t \)-string basis then the longest string in it has 
length equal to the index of nilpotency of $t$.
\end{lemma}

\begin{proof}
Suppose not.
Those strings cannot be longer; if the index is
\( k \) then \( t^k \) sends any vector\Dash including those starting the
string\Dash to \( \zero \).
So suppose instead that there is a transformation $t$ of index~$k$ 
on some space, such that the space has a $t$-string basis where 
all of the strings are shorter than length \( k \).
Because $t$ has index~$k$, there is a vector \( \vec{v} \) 
such that \( t^{k-1}(\vec{v})\neq\zero \).
Represent $\vec{v}$ as a linear combination of basis elements 
and apply \( t^{k-1} \).
We are supposing that \( t^{k-1} \) sends each basis element to \( \zero \)
but that it does not send \( \vec{v} \) to \( \zero \).
That is impossible. 
\end{proof}

We shall show that every
nilpotent map has an associated string basis.
Then our goal theorem, that every
nilpotent matrix is similar to one that is
all zeros except for blocks of subdiagonal ones, is immediate,
as in \nearbyexample{ThirdNilMap}.

Looking for a counterexample, a nilpotent map without an associated
string basis that is disjoint, will suggest the idea for the proof.
Consider the map \( \map{t}{\C^5}{\C^5} \) with this action.
\begin{center}
  \begin{minipage}{1in}
  $\begin{strings}{ccccc}
     \setlength{\unitlength}{1pt}
     \begin{picture}(4,15)(0,0)
       \put(0,14){$\vec{e}_1$}
       \put(0,-12){$\vec{e}_2$}
     \end{picture}
     &\begin{picture}(8,10)(0,0)
       \put(0,8){\rotatebox{-30}{$\mapsto$}}%  
       \put(0,-8){\rotatebox{30}{$\mapsto$}}
     \end{picture}
     &\vec{e}_3 &\mapsto &\zero  \\[4ex]
     \vec{e}_4&\mapsto &\vec{e}_5 &\mapsto &\zero  
  \end{strings}$
  \end{minipage}
  \hspace*{3em}
  $\rep{t}{\stdbasis_5,\stdbasis_5}=
  \begin{mat}[r]
    0  &0  &0  &0  &0  \\
    0  &0  &0  &0  &0  \\
    1  &1  &0  &0  &0  \\
    0  &0  &0  &0  &0  \\
    0  &0  &0  &1  &0
  \end{mat}$
\end{center}
Even after ommitting the zero vector, these three 
strings aren't disjoint, but that doesn't end hope of finding a 
$t$-string basis.
It only means that \( \stdbasis_5 \) will not do for the string basis.

To find a basis that will do, we first find 
the number and lengths of its strings.
Since $t$'s index of nilpotency is two,
\nearbylemma{le:LongestTowerIsIndex} says that 
at least one string in the basis has length two.
Thus the map must act on a string basis in one of these two ways.
\begin{equation*}
  \begin{strings}{ccccc}
    \vec{\beta}_1 &\mapsto &\vec{\beta}_2 &\mapsto &\zero  \\
    \vec{\beta}_3 &\mapsto &\vec{\beta}_4 &\mapsto &\zero  \\
    \vec{\beta}_5 &\mapsto &\zero
  \end{strings}
  \hspace*{3em}
  \begin{strings}{ccccc}
    \vec{\beta}_1 &\mapsto &\vec{\beta}_2 &\mapsto &\zero  \\
    \vec{\beta}_3 &\mapsto &\zero   \\
    \vec{\beta}_4 &\mapsto &\zero   \\
    \vec{\beta}_5 &\mapsto &\zero
  \end{strings}
\end{equation*}
Now, the key point.
A transformation with the left-hand action has a
nullspace of dimension three since that's how many basis vectors are
sent to zero. 
A transformation with the right-hand action has a nullspace of
dimension four.
Using the matrix representation above, calculation of $t$'s nullspace
\begin{equation*}
  \nullspace{t}=
  \set{\colvec{x \\ -x \\ z \\ 0 \\ r}\suchthat x,z,r\in\C }
\end{equation*}
shows that it is three-dimensional,
meaning that we want the left-hand action.

To produce a string basis, first
pick \( \vec{\beta}_2 \) and \( \vec{\beta}_4 \) from
\( \rangespace{t}\intersection\nullspace{t} \)
\begin{equation*}
  \vec{\beta}_2=\colvec[r]{0 \\ 0 \\ 1 \\ 0 \\ 0}\qquad
  \vec{\beta}_4=\colvec[r]{0 \\ 0 \\ 0 \\ 0 \\ 1}
\end{equation*}
(other choices are possible, just be sure that 
\( \set{\vec{\beta}_2,\vec{\beta}_4} \) is linearly independent).
For \( \vec{\beta}_5 \) pick a vector from \( \nullspace{t} \)
that is not in the span of \( \set{ \vec{\beta}_2,\vec{\beta}_4 } \).
\begin{equation*}
  \vec{\beta}_5=\colvec[r]{1 \\ -1 \\ 0 \\ 0 \\ 0}
\end{equation*}
Finally, take \( \vec{\beta}_1 \) and \( \vec{\beta}_3 \) such that
\( t(\vec{\beta}_1)=\vec{\beta}_2 \) and
\( t(\vec{\beta}_3)=\vec{\beta}_4 \).
\begin{equation*}
  \vec{\beta}_1=\colvec[r]{0 \\ 1 \\ 0 \\ 0 \\ 0}\qquad
  \vec{\beta}_3=\colvec[r]{0 \\ 0 \\ 0 \\ 1 \\ 0}
\end{equation*}
Now, with respect to \( B=\sequence{\vec{\beta}_1,\ldots,\vec{\beta}_5} \),
the matrix of $t$ is as desired.
\begin{equation*}
  \rep{t}{B,B}=
  \begin{pmat}{rr|rr|r}
    0  &0  &0  &0  &0  \\
    1  &0  &0  &0  &0  \\  \hline
    0  &0  &0  &0  &0  \\
    0  &0  &1  &0  &0  \\  \hline
    0  &0  &0  &0  &0
  \end{pmat}
\end{equation*}

\begin{theorem}
\label{th:NilMapHasStrBas}
Any nilpotent transformation $t$ is associated with a \( t \)-string basis.
While the basis is not unique, the number
and the length of the strings is determined by \( t \).
\end{theorem}

\begin{proof}
This illustrates the argument below, which describes three kinds of
basis vectors (these basis vectors are shown as squares or circles, 
according to whether they are in the nullspace or not).
\begin{equation*}
   \begin{strings}{ccccccccccccccccccc}
     \digitincirc{3}
         &\mapsto &\digitincirc{1} &\mapsto
         &\cdots &  &  &  &  &  &  &  &\cdots
         &\mapsto &\digitincirc{1}
         &\mapsto &\digitinsq{1} &\mapsto &\zero  \\[.75ex]
     \digitincirc{3}
         &\mapsto &\digitincirc{1} &\mapsto
         &\cdots &  &  &  &  &  &  &  &\cdots
         &\mapsto &\digitincirc{1}
         &\mapsto &\digitinsq{1} &\mapsto &\zero  \\[.75ex]
         &\smash{\vdotswithin{\mapsto}}  \\
     \digitincirc{3}
         &\mapsto &\digitincirc{1} &\mapsto
         &\cdots &
         &\mapsto &\digitincirc{1}
         &\mapsto &\digitinsq{1} &\mapsto &\zero  \\[.75ex]
     \digitinsq{2} &\mapsto &\zero \\[.75ex]
         &\smash{\vdotswithin{\mapsto}}  \\
     \digitinsq{2} &\mapsto &\zero
   \end{strings}
\end{equation*}

Fix a vector space $V$; we will argue by induction on the index of nilpotency
of $\map{t}{V}{V}$.
If that index is \( 1 \) then \( t \) is the zero map and any basis 
is a string basis $\vec{\beta}_1\mapsto\zero$, \ldots, 
$\vec{\beta}_n\mapsto\zero$.
For the inductive step, assume that the theorem holds for any transformation
with an index of nilpotency between $1$ and \( k-1 \)
and consider the index~$k$ case.

First observe that the restriction to
the rangespace
\( \map{t}{\rangespace{t}}{\rangespace{t}} \) 
is also nilpotent, of index \( k-1 \).
Apply the inductive hypothesis to get a string basis for
\( \rangespace{t} \),
where the number and length of the strings
is determined by \( t \).
\begin{equation*}
  B=\cat{\cat{\sequence{\vec{\beta}_1,t(\vec{\beta}_1),\dots,
     t^{h_1}(\vec{\beta}_1)}}{
  \cat{\sequence{\vec{\beta}_2,\ldots,t^{h_2}(\vec{\beta}_2)}}}{\cdots}}{
  \sequence{\vec{\beta}_i,\ldots,t^{h_i}(\vec{\beta}_i)} }
\end{equation*}
(In the illustration these are the basis vectors of kind~\( 1 \),
so there are $i$ strings shown with this kind of basis vector.)

Second, note that taking the final nonzero vector in each string
gives a basis
\( C=\sequence{t^{h_1}(\vec{\beta}_1),\dots,t^{h_i}(\vec{\beta}_i)} \)
for \( \rangespace{t}\intersection\nullspace{t} \).
(These are illustrated with \( 1 \)'s in squares.)
For, a member of \( \rangespace{t} \) is mapped to zero if and only
if it is a linear combination of those basis vectors that are mapped
to zero.
Extend \( C \) to a basis for all of \( \nullspace{t} \).
\begin{equation*}
  \hat{C}=\cat{C}{\sequence{\vec{\xi}_1,\dots,\vec{\xi}_p}}
\end{equation*}
(The $\vec{\xi}$'s are the vectors of kind~\( 2 \) 
so that \( \hat{C} \) is the set of squares.)
While many choices are possible for the \( \vec{\xi} \)'s,
their number \( p \) is determined by the map \( t \) as it is the dimension of
\( \nullspace{t} \) minus the dimension of
\( \rangespace{t}\intersection\nullspace{t} \).

Finally, \( \cat{B}{\hat{C}} \)
is a basis for \( \rangespace{t}+\nullspace{t} \)
because any sum of something in the rangespace with something in the nullspace
can be represented using elements of \( B \) for the rangespace 
part and elements of \( \hat{C} \) for the part from the nullspace.
Note that
\begin{align*}
  \dim\big(\rangespace{t}+\nullspace{t}\big)
  &=
  \dim (\rangespace{t})+\dim (\nullspace{t})
    -\dim(\rangespace{t}\intersection\nullspace{t})  \\
  &=
  \rank (t)+\nullity (t)-i          \\
  &=
  \dim (V)-i
\end{align*}
and so \( \cat{B}{\hat{C}} \) can be extended to a basis for all of 
\( V \) by the addition of \( i \) more vectors.
Specifically, remember that each of \( \vec{\beta}_1,\dots,\vec{\beta}_i \) is
in \( \rangespace{t} \), and extend \( \cat{B}{\hat{C}} \) with vectors
\( \vec{v}_1,\dots,\vec{v}_i \) such that
\( t(\vec{v}_1)=\vec{\beta}_1,\dots,t(\vec{v}_i)=\vec{\beta}_i \).
(In the illustration, these are the \( 3 \)'s.)
The check that linear independence is preserved by this extension is
\nearbyexercise{exer:NilMapWillHaveStrBas}.
\end{proof}

\begin{corollary}
\index{nilpotent!canonical form for}
\index{transformation!nilpotent!canonical representative}
\index{canonical form!for nilpotent matrices}
Every nilpotent matrix is similar to a matrix that is all zeros
except for blocks of subdiagonal ones.
That is, every nilpotent map is represented with respect to some basis by
such a matrix.
\end{corollary}

This form is unique in the sense that if a nilpotent matrix is similar to two
such matrices then those two simply have their blocks ordered differently.
Thus this is
a canonical form for the similarity classes of nilpotent matrices
provided that we order the blocks, say, from longest to shortest.

\begin{example}
The matrix
\begin{equation*}
  M=\begin{mat}[r]
      1  &-1  \\
      1  &-1
    \end{mat}
\end{equation*}
has an index of nilpotency of two, as this calculation shows.
\begin{center}
  \begin{tabular}{c|cc}
    \( p \)  &\( M^p \)  &\( \nullspace{M^p}  \)   \\  \hline
    \( 1 \)
    &\(  M=\begin{mat}[r]
         1  &-1  \\
         1  &-1
       \end{mat}  \)
    &\( \set{\colvec{x \\ x}\suchthat
                               x\in\C}  \)   \\[2ex]
    \( 2 \)
    &\(  M^2=\begin{mat}[r]
         0  &0   \\
         0  &0
       \end{mat}  \)
    &\( \C^2  \)
  \end{tabular}
\end{center}
The calculation also describes how a map $m$ represented by $M$ must act on any
string basis.
With one map application the nullspace has dimension~one and so one
vector of the basis is sent to zero.
On a second application, the nullspace has dimension~two and so
the other basis vector is sent to zero. 
Thus, the action of the map is
$\vec{\beta}_1\mapsto\vec{\beta}_2\mapsto\zero$ 
and the canonical form of the matrix is this.
\begin{equation*}
  \begin{mat}[r]
    0  &0  \\
    1  &0
  \end{mat}
\end{equation*}

We can exhibit such a $m$-string basis 
and the change of basis matrices witnessing the matrix similarity.
For the basis,
take \( M \) to represent $m$ with respect to the standard bases,
pick a \( \vec{\beta}_2\in\nullspace{m} \)
and also pick a \( \vec{\beta}_1 \) 
so that \( m(\vec{\beta}_1)=\vec{\beta}_2 \).
\begin{equation*}
  \vec{\beta}_2=\colvec[r]{1 \\ 1}
  \qquad
  \vec{\beta}_1=\colvec[r]{1 \\ 0}
\end{equation*}
(If we take $M$ to be a representative with respect to some nonstandard bases
then this picking step is just more messy.)
Recall the similarity diagram.
\begin{equation*}
  \begin{CD}
    \C^2_\wrt{\stdbasis_2}      @>m>M>        \C^2_\wrt{\stdbasis_2}     \\
    @V\scriptstyle\identity V\scriptstyle PV  @V\scriptstyle\identity V\scriptstyle PV \\
    C^2_\wrt{B}                 @>m>>         \C^2_\wrt{B}
  \end{CD}
\end{equation*}
The canonical form equals \( \rep{m}{B,B}=PMP^{-1} \), where
\begin{equation*}
   P^{-1} %=\bigl(\rep{\identity}{\stdbasis_2,B}\bigr)^{-1}
         =\rep{\identity}{B,\stdbasis_2}
         =\begin{mat}[r]
            1  &1  \\
            0  &1
          \end{mat}
   \qquad
   P=(P^{-1})^{-1}
         =\begin{mat}[r]
            1  &-1  \\
            0  &1
          \end{mat}
\end{equation*}
and the verification of the matrix calculation is routine.
\begin{equation*}
  \begin{mat}[r]
    1  &-1  \\
    0  &1
  \end{mat}
  \begin{mat}[r]
    1  &-1  \\
    1  &-1
  \end{mat}
  \begin{mat}[r]
    1  &1  \\
    0  &1
  \end{mat}=
  \begin{mat}[r]
    0  &0  \\
    1  &0
  \end{mat}
\end{equation*}
%which does indeed describe the effect of $m$ on the string basis.
\end{example}

\begin{example} \label{ex:FiveByNilStrBas}
The matrix
\begin{equation*}
  \begin{mat}[r]
     0  &0  &0  &0  &0  \\
     1  &0  &0  &0  &0  \\
     -1 &1  &1  &-1 &1  \\
     0  &1  &0  &0  &0  \\
     1  &0  &-1 &1  &-1
  \end{mat}
\end{equation*}
is nilpotent.
These calculations show the nullspaces growing. 
\begin{center}
  \begin{tabular}{c|cc}
    \( p \)  &\( N^p \)  &\( \nullspace{N^p}  \)   \\  \hline
    \( 1 \)
    &\(\begin{mat}[r]
         0  &0  &0  &0  &0  \\
         1  &0  &0  &0  &0  \\
         -1 &1  &1  &-1 &1  \\
         0  &1  &0  &0  &0  \\
         1  &0  &-1 &1  &-1
       \end{mat}  \)
    &\( \set{\colvec{0 \\ 0 \\ u-v \\ u \\ v} \suchthat u,v\in\C}  \) \\[2.4ex]
    \( 2 \)
    &\(\begin{mat}[r]
         0  &0  &0  &0  &0  \\
         0  &0  &0  &0  &0  \\
         1  &0  &0  &0  &0  \\
         1  &0  &0  &0  &0  \\
         0  &0  &0  &0  &0
       \end{mat}  \)
    &\( \set{\colvec{0 \\ y \\ z \\ u \\ v}
                       \suchthat y,z,u,v\in\C}  \)  \\[2.4ex]
    \( 3 \)
    &\textit{--zero matrix--}
    &\( \C^5 \)
  \end{tabular}
\end{center}
That table shows that any string basis must satisfy:~the 
nullspace after one map application has
dimension~two so two basis vectors are sent directly to zero, 
the nullspace after the second application has dimension four 
so two additional basis vectors are sent to zero by the second iteration, and
the nullspace after three applications is of dimension~five so the final
basis vector is sent to zero in three hops.
\begin{equation*}
  \begin{strings}{ccccccc}
    \vec{\beta}_1 &\mapsto &\vec{\beta}_2 &\mapsto &\vec{\beta}_3
       &\mapsto &\zero  \\
    \vec{\beta}_4 &\mapsto &\vec{\beta}_5 &\mapsto &\zero
  \end{strings}
\end{equation*}
To produce such a basis, first pick two independent vectors from
\( \nullspace{n} \)
\begin{equation*}
   \vec{\beta}_3=\colvec[r]{0 \\ 0 \\ 1 \\ 1 \\ 0} \quad
   \vec{\beta}_5=\colvec[r]{0 \\ 0 \\ 0 \\ 1 \\ 1}
\end{equation*}
then add \( \vec{\beta}_2,\vec{\beta}_4\in\nullspace{n^2} \)
such that \( n(\vec{\beta}_2)=\vec{\beta}_3 \) and
\( n(\vec{\beta}_4)=\vec{\beta}_5 \)
\begin{equation*}
   \vec{\beta}_2=\colvec[r]{0 \\ 1 \\ 0 \\ 0 \\ 0} \quad
   \vec{\beta}_4=\colvec[r]{0 \\ 1 \\ 0 \\ 1 \\ 0}
\end{equation*}
and finish by adding \( \vec{\beta}_1\in\nullspace{n^3}=\C^5 \)) 
such that \( n(\vec{\beta}_1)=\vec{\beta}_2 \).
\begin{equation*}
   \vec{\beta}_1=\colvec[r]{1 \\ 0 \\ 1 \\ 0 \\ 0}
\end{equation*}
\end{example}






\begin{exercises}
   \recommended \item \label{exer:IndNilLftShift}
     What is the index of nilpotency of the \definend{left-shift} operator,
     here acting on the space of triples of reals?
      \begin{equation*}
         (x,y,z)\mapsto(0,x,y)
      \end{equation*}
      \begin{answer}
        Three.  
        It is at least three because $\ell^2(\,(1,1,1)\,)=(0,0,1)\neq \zero$.
        It is at most three because 
        $(x,y,z)\mapsto (0,x,y)\mapsto (0,0,x)\mapsto (0,0,0)$.
      \end{answer}
  \recommended \item 
    For each string basis state the index of nilpotency and
    give the dimension of the rangespace and
    nullspace of each iteration of the nilpotent map.
    \begin{exparts}
      \partsitem $
        \begin{strings}{ccccccc}
           \vec{\beta}_1 &\mapsto &\vec{\beta}_2 &\mapsto &\zero  \\
           \vec{\beta}_3 &\mapsto &\vec{\beta}_4 &\mapsto &\zero  
         \end{strings}$
      \partsitem $
        \begin{strings}{ccccccc}
           \vec{\beta}_1 &\mapsto &\vec{\beta}_2 &\mapsto &\vec{\beta}_3
                &\mapsto &\zero  \\
           \vec{\beta}_4 &\mapsto &\zero \\
           \vec{\beta}_5 &\mapsto &\zero \\
           \vec{\beta}_6 &\mapsto &\zero
         \end{strings}$
      \partsitem $
        \begin{strings}{ccccccccc}
           \vec{\beta}_1 &\mapsto &\vec{\beta}_2 &\mapsto &\vec{\beta}_3
                &\mapsto &\zero  
         \end{strings}$
    \end{exparts}
    Also give the canonical form of the matrix.
    \begin{answer}
      \begin{exparts}
        \partsitem The domain has dimension four.
          The map's action is that any vector in the space
          $c_1\cdot \vec{\beta}_1+c_2\cdot \vec{\beta}_2
            +c_3\cdot \vec{\beta}_3+c_4\cdot \vec{\beta}_4$
          is sent to
          $c_1\cdot \vec{\beta}_2+c_2\cdot \zero
            +c_3\cdot \vec{\beta}_4+c_4\cdot \zero
           =c_1\cdot \vec{\beta}_3+c_3\cdot\vec{\beta}_4$.
          The first application of the map
          sends two basis vectors $\vec{\beta}_2$ and
          $\vec{\beta}_4$ to zero,
          and therefore the nullspace has dimension~two and the rangespace
          has dimension~two.
          With a second application, all four basis vectors are sent to
          zero and so the nullspace of the second power has dimension~four
          while the rangespace of the second power has dimension~zero.
          Thus the index of nilpotency is two.
          This is the canonical form.
          \begin{equation*}
            \begin{mat}[r]
              0  &0  &0  &0  \\
              1  &0  &0  &0  \\
              0  &0  &0  &0  \\
              0  &0  &1  &0
            \end{mat}
          \end{equation*}
        \partsitem The dimension of the domain of this map is six.
          For the first power the dimension of the nullspace is four
          and the dimension of the rangespace is two.
          For the second power the dimension of the nullspace is five
          and the dimension of the rangespace is one.
          Then the third iteration results in a nullspace of dimension
          six and a rangespace of dimension zero.
          The index of nilpotency is three, and this is the
          canonical form.
          \begin{equation*}
            \begin{mat}[r]
              0  &0  &0  &0  &0  &0  \\
              1  &0  &0  &0  &0  &0  \\
              0  &1  &0  &0  &0  &0  \\
              0  &0  &0  &0  &0  &0  \\              
              0  &0  &0  &0  &0  &0  \\              
              0  &0  &0  &0  &0  &0  
            \end{mat}
          \end{equation*}
        \partsitem The dimension of the domain is three, and the index of 
          nilpotency is three.
          The first power's null space has dimension one and its range space
          has dimension two.
          The second power's null space has dimension two and its range space
          has dimension one.
          Finally, the third power's null space has dimension three 
          and its range space
          has dimension zero.
          Here is the canonical form matrix.
          \begin{equation*}
            \begin{mat}[r]
              0  &0  &0  \\
              1  &0  &0  \\
              0  &1  &0 
            \end{mat}
          \end{equation*}
      \end{exparts}
    \end{answer}
  \item 
    Decide which of these matrices are nilpotent.
    \begin{exparts*}
      \partsitem 
        $\begin{mat}[r]
           -2  &4  \\
           -1  &2
        \end{mat}$
      \partsitem 
        $\begin{mat}[r]
          3  &1  \\
          1  &3
        \end{mat}$
      \partsitem 
        $\begin{mat}[r]
          -3  &2  &1  \\
          -3  &2  &1  \\
          -3  &2  &1
        \end{mat}$
      \partsitem 
        $\begin{mat}[r]
           1  &1  &4  \\
           3  &0  &-1 \\
           5  &2  &7
        \end{mat}$
      \partsitem 
        $\begin{mat}[r]
           45  &-22  &-19  \\
           33  &-16  &-14  \\
           69  &-34  &-29
        \end{mat}$
    \end{exparts*}
    \begin{answer}
      By \nearbylemma{le:RangeAndNullChains} the nullity has grown as 
      large as possible by the $n$-th iteration where $n$ is the dimension
      of the domain.
      Thus, for the $\nbyn{2}$ matrices, 
      we need only check whether the square is the zero matrix.
      For the $\nbyn{3}$ matrices, we need only check the cube.
      \begin{exparts}
        \partsitem Yes, this matrix is nilpotent because
          its square is the zero matrix.
        \partsitem No, the square is not the zero matrix.
          \begin{equation*}
            \begin{mat}[r]
               3  &1  \\
               1  &3
            \end{mat}^2
            =\begin{mat}[r]
               10  &6  \\
               6   &10
            \end{mat}
          \end{equation*}
        \partsitem Yes, the cube is the zero matrix.
          In fact, the square is zero.
        \partsitem No, the third power is not the zero matrix.
          \begin{equation*}
            \begin{mat}[r]
              1  &1  &4  \\
              3  &0  &-1 \\
              5  &2  &7
            \end{mat}^3
            =\begin{mat}[r]
              206  &86  &304  \\
               26  &8   &26   \\
              438  &180 &634
            \end{mat}
          \end{equation*}
        \partsitem Yes, the cube of this matrix is the zero matrix.
      \end{exparts}
      Another way to see that the second and fourth matrices are not nilpotent
      is to note that they are nonsingular.
    \end{answer}
  \recommended \item 
    Find the canonical form of this matrix.
    \begin{equation*}
      \begin{mat}[r]
        0  &1  &1  &0  &1  \\
        0  &0  &1  &1  &1  \\
        0  &0  &0  &0  &0  \\
        0  &0  &0  &0  &0  \\
        0  &0  &0  &0  &0
      \end{mat}
    \end{equation*}
    \begin{answer} The table os calculations
      \begin{center}
          \begin{tabular}{c|cc}
             \( p \)  &\( N^p \)  &\( \nullspace{N^p}  \)   \\  \hline
             \( 1 \)
               &\(\begin{mat}[r]
                   0  &1  &1  &0  &1  \\
                   0  &0  &1  &1  &1  \\
                   0  &0  &0  &0  &0  \\
                   0  &0  &0  &0  &0  \\
                   0  &0  &0  &0  &0
                  \end{mat}  \)
               &\( \set{\colvec{r \\ u \\ -u-v \\ u \\ v} 
                              \suchthat r,u,v\in\C}  \) \\[4ex]
             \( 2 \)
               &\(\begin{mat}[r]
                   0  &0  &1  &1  &1  \\
                   0  &0  &0  &0  &0  \\
                   0  &0  &0  &0  &0  \\
                   0  &0  &0  &0  &0  \\
                   0  &0  &0  &0  &0
                  \end{mat}  \)
               &\( \set{\colvec{r \\ s \\ -u-v \\ u \\ v} 
                              \suchthat r,s,u,v\in\C}  \) \\[3ex]
            \( 2 \)
               &\textit{--zero matrix--}
               &\( \C^5 \)
          \end{tabular}
        \end{center}
        gives these requirements of the string basis:~three basis vectors
        are sent directly to zero, one more basis vector is sent to zero by a
        second application, and the final basis vector 
        is sent to zero by a third application.
        Thus, the string basis has this form.
        \begin{equation*}
          \begin{strings}{ccccccc}
            \vec{\beta}_1 &\mapsto &\vec{\beta}_2 &\mapsto 
              &\vec{\beta}_3 &\mapsto &\zero               \\
            \vec{\beta}_4 &\mapsto &\zero                  \\
            \vec{\beta}_5 &\mapsto &\zero  
          \end{strings}
        \end{equation*}
        From that the canonical form is immediate.
        \begin{equation*}
          \begin{mat}[r]
            0  &0  &0  &0  &0  \\
            1  &0  &0  &0  &0  \\
            0  &1  &0  &0  &0  \\
            0  &0  &0  &0  &0  \\
            0  &0  &0  &0  &0
          \end{mat}
        \end{equation*}
    \end{answer}
  \recommended \item 
    Consider the matrix from \nearbyexample{ex:FiveByNilStrBas}.
    \begin{exparts}
      \partsitem Use the action of the map on the string basis to
        give the canonical form.
      \partsitem Find the change of basis matrices that bring the matrix
        to canonical form.
      \partsitem Use the answer in the prior item to check the answer in the 
        first item.
    \end{exparts}
    \begin{answer}
      \begin{exparts}
        \partsitem The canonical form has a $\nbyn{3}$ block and a 
          $\nbyn{2}$ block
          \begin{equation*}
            \begin{pmat}{rrr|rr}
              0  &0  &0  &0  &0  \\
              1  &0  &0  &0  &0  \\
              0  &1  &0  &0  &0  \\ \hline
              0  &0  &0  &0  &0  \\
              0  &0  &0  &1  &0  \\
            \end{pmat}
          \end{equation*}
          corresponding to the length three string and the length two
          string in the basis.
        \partsitem Assume that $N$ is the representation of the underlying
          map with respect to the standard basis.
          Let $B$ be the basis to which we will change. 
          By the similarity diagram
          \begin{equation*}
            \begin{CD}
              \C^2_\wrt{\stdbasis_2}      
                  @>n>N>        
                  \C^2_\wrt{\stdbasis_2}     \\
             @V\scriptstyle\identity V\scriptstyle PV  
                 @V\scriptstyle\identity V\scriptstyle PV \\
             C^2_\wrt{B}                 
                 @>n>>         
             \C^2_\wrt{B}
           \end{CD}
         \end{equation*}
         we have that the canonical form matrix is $PNP^{-1}$ where 
         \begin{equation*}
           P^{-1}
           =\rep{\identity}{B,\stdbasis_5}
           =\begin{mat}[r]
              1 &0 &0 &0 &0 \\              
              0 &1 &0 &1 &0 \\
              1 &0 &1 &0 &0 \\
              0 &0 &1 &1 &1 \\
              0 &0 &0 &0 &1
            \end{mat}
         \end{equation*}
         and $P$ is the inverse of that.
         \begin{equation*}
           P=\rep{\identity}{\stdbasis_5,B}
            =(P^{-1})^{-1}
           =\begin{mat}[r]
              1 &0 &0 &0 &0 \\              
             -1 &1 &1 &-1&1 \\
             -1 &0 &1 &0 &0 \\
              1 &0 &-1&1 &-1\\
              0 &0 &0 &0 &1
            \end{mat}
         \end{equation*}
        \partsitem The calculation to check this is routine.
      \end{exparts}
    \end{answer}
  \recommended \item
    Each of these matrices is nilpotent.
    \begin{exparts*}
      \partsitem \(
        \begin{mat}[r]
          1/2  &-1/2  \\
          1/2  &-1/2
        \end{mat}        \)
      \partsitem \(
        \begin{mat}[r]
          0  &0  &0  \\
          0  &-1 &1  \\
          0  &-1 &1
        \end{mat}        \)
      \partsitem \(
        \begin{mat}[r]
         -1  &1  &-1 \\
          1  &0  &1  \\
          1  &-1 &1
        \end{mat}        \)
    \end{exparts*}
    Put each in canonical form.
    \begin{answer}
      \begin{exparts*}
      \partsitem The calculation 
        \begin{center}
          \begin{tabular}{c|cc}
             \( p \)  &\( N^p \)  &\( \nullspace{N^p}  \)   \\  \hline
             \( 1 \)
               &\(\begin{mat}[r]
                    1/2  &-1/2  \\
                    1/2  &-1/2 
                  \end{mat}  \)
               &\( \set{\colvec{u \\ u} 
                              \suchthat u\in\C}  \) \\[2ex]
            \( 2 \)
               &\textit{--zero matrix--}
               &\( \C^2 \)
          \end{tabular}
        \end{center}
        shows that any map represented by the matrix
        must act on the string basis in this way 
        \begin{equation*}
          \begin{strings}{ccccccc}
            \vec{\beta}_1 &\mapsto &\vec{\beta}_2  &\mapsto &\zero  
          \end{strings}
        \end{equation*}
        because the nullspace after one application has dimension~one
        and exactly one basis vector, $\vec{\beta}_2$, is sent to zero.
        Therefore, this representation with respect to
        $\sequence{\vec{\beta}_1,\vec{\beta}_2}$ is the canonical form.
        \begin{equation*}
          \begin{mat}[r]
            0    &0   \\
            1    &0
          \end{mat}        
        \end{equation*}
      \partsitem The calculation here is similar to the prior one.
        \begin{center}
          \begin{tabular}{c|cc}
             \( p \)  &\( N^p \)  &\( \nullspace{N^p}  \)   \\  \hline
             \( 1 \)
               &\(\begin{mat}[r]
                    0  &0  &0  \\
                    0  &-1 &1  \\
                    0  &-1 &1  
                  \end{mat}  \)
               &\( \set{\colvec{u \\ v \\ v} 
                              \suchthat u,v\in\C}  \) \\[2ex]
           \( 2 \)
               &\textit{--zero matrix--}
               &\( \C^3 \)
          \end{tabular}
       \end{center}
       The table shows that the string basis is of the form
        \begin{equation*}
          \begin{strings}{ccccccc}
            \vec{\beta}_1 &\mapsto &\vec{\beta}_2 &\mapsto &\zero  \\
            \vec{\beta}_3 &\mapsto &\zero
          \end{strings}
        \end{equation*}
        because the nullspace after one application of the map has 
        dimension two\Dash
        $\vec{\beta}_2$ and $\vec{\beta}_3$ are both sent to zero\Dash and
        one more iteration results in the additional vector being brought
        to zero.
      \partsitem The calculation 
        \begin{center}
          \begin{tabular}{c|cc}
             \( p \)  &\( N^p \)  &\( \nullspace{N^p}  \)   \\  \hline
             \( 1 \)
               &\(\begin{mat}[r]
                    -1  &1  &-1  \\
                     1  &0  &1   \\
                     1  &-1 &1 
                  \end{mat}  \)
               &\( \set{\colvec{u \\ 0 \\ -u} 
                              \suchthat u\in\C}  \) \\[2ex]
             \( 2 \)
               &\(\begin{mat}[r]
                     1  &0  &1   \\
                     0  &0  &0   \\
                    -1  &0  &-1
                  \end{mat}  \)
               &\( \set{\colvec{u \\ v \\ -u} 
                              \suchthat u,v\in\C}  \) \\[2ex]
            \( 3 \)
               &\textit{--zero matrix--}
               &\( \C^3 \)
          \end{tabular}
        \end{center}
        shows that any map represented by this basis must act on 
        a string basis in this way. 
        \begin{equation*}
          \begin{strings}{ccccccc}
            \vec{\beta}_1 &\mapsto &\vec{\beta}_2 &\mapsto 
              &\vec{\beta}_3 &\mapsto &\zero  
          \end{strings}
        \end{equation*}
        Therefore, this is the canonical form.
        \begin{equation*}
          \begin{mat}[r]
            0    &0   &0   \\
            1    &0   &0   \\
            0    &1   &0
          \end{mat}        
        \end{equation*}
      \end{exparts*}  
     \end{answer}
  \item 
    Describe the effect of left or right multiplication by a matrix that is
    in the canonical form for nilpotent matrices.
    \begin{answer}
      A couple of examples 
      \begin{equation*}
        \begin{mat}[r]
          0  &0  \\
          1  &0
        \end{mat}
        \begin{mat}
          a  &b  \\
          c  &d
        \end{mat}
        =
        \begin{mat}
          0  &0  \\
          a  &b  
        \end{mat}
        \qquad
        \begin{mat}[r]
          0  &0  &0 \\
          1  &0  &0 \\
          0  &1  &0
        \end{mat}
        \begin{mat}
          a  &b  &c \\
          d  &e  &f \\
          g  &h  &i
        \end{mat}
        =
        \begin{mat}
          0  &0  &0 \\
          a  &b  &c \\
          d  &e  &f
        \end{mat}
      \end{equation*}
      suggest that left multiplication by a block of subdiagonal ones
      shifts the rows of a matrix downward.
      Distinct blocks
      \begin{equation*}
        \begin{mat}[r]
          0  &0  &0  &0  \\
          1  &0  &0  &0  \\
          0  &0  &0  &0  \\
          0  &0  &1  &0
        \end{mat}
        \begin{mat}
          a  &b  &c  &d  \\
          e  &f  &g  &h  \\
          i  &j  &k  &l  \\
          m  &n  &o  &p
        \end{mat}
        =
        \begin{mat}
          0  &0  &0  &0  \\
          a  &b  &c  &d  \\       
          0  &0  &0  &0  \\
          i  &j  &k  &l  
        \end{mat}
      \end{equation*}
      act to shift down distinct parts of the matrix.

      Right multiplication does an analgous thing to columns.
      See \nearbyexercise{exer:IndNilLftShift}.
    \end{answer}
  \item 
    Is nilpotence invariant under similarity?
    That is, must a matrix similar to a nilpotent matrix also be nilpotent?
    If so, with the same index?
    \begin{answer}
      Yes.
      Generalize the last sentence in \nearbyexample{ex:NilMatNotCanon}.
      As to the index, that same last sentence shows that the index of the new 
      matrix is less than or equal to the index of $\hat{N}$, and reversing
      the roles of the two matrices gives inequality in the other direction.

      Another answer to this question is to show that a matrix is 
      nilpotent if and only if any associated map is nilpotent, and 
      with the same index.
      Then, because similar matrices represent the same map, the conclusion
      follows.
      This is \nearbyexercise{exer:MatNilIffMapNil} below.
    \end{answer}  
  \recommended \item
    Show that the only eigenvalue of a nilpotent matrix is zero.
    \begin{answer}
      Observe that a canonical form nilpotent matrix has only
      zero eigenvalues; e.g., the determinant of this lower-triangular matrix
      \begin{equation*}
         \begin{mat}
           -x  &0  &0  \\
            1  &-x &0  \\
            0  &1  &-x
         \end{mat}
      \end{equation*}
      is \( (-x)^3 \), the only root of which is zero.
      But similar matrices have the same eigenvalues and every nilpotent
      matrix is similar to one in canonical form.   

      Another way to see this is to observe that a nilpotent matrix sends all
      vectors to zero after some number of iterations, but that conflicts 
      with an action on an eigenspace $\vec{v}\mapsto \lambda\vec{v}$ unless
      $\lambda$ is zero.
    \end{answer}
  \item 
    Is there a nilpotent transformation of index three on a
    two-dimensional space?
    \begin{answer}
      No, by \nearbylemma{le:RangeAndNullChains} for a map on a 
      two-dimensional space, the nullity has grown
      as large as possible by the second iteration.
    \end{answer}
  \item 
    In the proof of \nearbytheorem{th:NilMapHasStrBas}, why isn't the
    proof's base case that the index of nilpotency is zero?
    \begin{answer}
      The index of nilpotency of a transformation can be zero only when the 
      vector starting the string
      must be $\zero$, that is, only when $V$ is a trivial space.
    \end{answer}
  \recommended \item
    Let \( \map{t}{V}{V} \) be a linear transformation and suppose
    \( \vec{v}\in V \)  is such that \( t^k(\vec{v})=\zero \) but
    \( t^{k-1}(\vec{v})\neq\zero \).
    Consider the $t$-string 
    $\sequence{\vec{v},t(\vec{v}),\dots,t^{k-1}(\vec{v})}$.
    \begin{exparts}
      \partsitem Prove that \( t \) is a transformation on the span of the set
        of vectors in the string,
        that is, prove that \( t \) restricted to the span has a range
        that is a subset of the span.
        We say that the span is a \definend{\( t \)-invariant} 
        subspace.\index{invariant!subspace}
      \partsitem Prove that the restriction is nilpotent.
      \partsitem Prove that the $t$-string
        is linearly independent and so is a basis for its span.
      \partsitem Represent the restriction map with respect to the 
        $t$-string basis.
    \end{exparts}
    \begin{answer}
      \begin{exparts}
        \partsitem Any member $\vec{w}$ of the span can be written as
          a linear combination
          $\vec{w}=c_0\cdot \vec{v}+c_1\cdot t(\vec{v})+\dots
           +c_{k-1}\cdot t^{k-1}(\vec{v})$.
          But then, by the linearity of the map, 
          $t(\vec{w})=c_0\cdot t(\vec{v})+c_1\cdot t^2(\vec{v})+\dots
           +c_{k-2}\cdot t^{k-1}(\vec{v})+c_{k-1}\cdot \zero$
          is also in the span.
        \partsitem The operation in the prior item, when iterated $k$ times,
          will result in a linear combination of zeros.    
        \partsitem If \( \vec{v}=\zero \) then the set is empty and so is
          linearly independent by definition.
          Otherwise write \( c_1\vec{v}+\dots+c_{k-1}t^{k-1}(\vec{v})=\zero \)
          and apply \( t^{k-1} \) to both sides.
          The right side gives \( \zero \) while the left side gives
          \( c_1t^{k-1}(\vec{v}) \); conclude that \( c_1=0 \).
          Continue in this way by applying \( t^{k-2} \) to both sides,
          etc.  
        \partsitem Of course, $t$ acts on the span by acting on
          this basis as a single, $k$-long, $t$-string.
          \begin{equation*}
            \begin{mat}
              0 &0 &0 &0 &\ldots &0 &0 \\
              1 &0 &0 &0 &\ldots &0 &0 \\
              0 &1 &0 &0 &\ldots &0 &0 \\
              0 &0 &1 &0 &       &0 &0 \\
                &  &  &\ddots          \\
              0 &0 &0 &0 &       &1 &0 \\
            \end{mat}
          \end{equation*}
      \end{exparts}
    \end{answer}
  \item \label{exer:NilMapWillHaveStrBas}
    Finish the proof of \nearbytheorem{th:NilMapHasStrBas}.
    \begin{answer}
      We must check that
      \( B\union\hat{C}\union\set{\vec{v}_1,\dots,\vec{v}_j} \) is linearly
      independent where \( B \) is a \( t \)-string basis for
      \( \rangespace{t} \), where \( \hat{C} \) is a basis for
      \( \nullspace{t} \), and where
      \( t(\vec{v}_1)=\vec{\beta}_1,\dots,t(\vec{v}_i=\vec{\beta}_i \).
      Write
      \begin{equation*}
        \zero=c_{1,-1}\vec{v}_1+c_{1,0}\vec{\beta}_1
               +c_{1,1}t(\vec{\beta}_1)+\dots+
               c_{1,{h_1}}t^{h_1}(\vec{\vec{\beta}}_1)
               +c_{2,-1}\vec{v}_2+\dots+c_{j,h_i}t^{h_i}(\vec{\beta_i})
      \end{equation*}
      and apply \( t \).
      \begin{equation*}
        \zero=c_{1,-1}\vec{\beta}_1+c_{1,0}t(\vec{\beta}_1)
               +\dots+
               c_{1,h_1-1}t^{h_1}(\vec{\vec{\beta}}_1)+c_{1,h_1}\zero
            +c_{2,-1}\vec{\beta}_2+\cdots+c_{i,h_i-1}t^{h_i}(\vec{\beta_i})
            +c_{i,h_i}\zero
      \end{equation*}
      Conclude that the coefficients \( c_{1,-1},\dots,c_{1,h_i-1},
      c_{2,-1},\dots,c_{i,h_i-1} \) are all zero as \( B\union\hat{C} \)
      is a basis.
      Substitute back into the first displayed equation to conclude that
      the remaining coefficients are zero also.  
    \end{answer}
  \item \label{exer:MatNilIffMapNil} 
    Show that the terms `nilpotent transformation' and `nilpotent matrix',
    as given in \nearbydefinition{def:nilpotent}, fit with each other:~a
    map is nilpotent if and only if it is represented by a 
    nilpotent matrix.
    (Is it that a transformation is nilpotent if an only if there is a basis
    such that the map's representation with respect to that basis is a
    nilpotent matrix, or that any representation is a nilpotent matrix?)
    \begin{answer}
      For any basis $B$,
      a transformation~$n$ is nilpotent if and only if 
      $N=\rep{n}{B,B}$ is a nilpotent matrix.
      This is because only the zero matrix represents the zero map
      and so \( n^j \) is the zero map if and only if \( N^j \) 
      is the zero matrix.
    \end{answer}
  \item 
    Let \( T \) be nilpotent of index four.
    How big can the rangespace of \( T^3 \) be?
    \begin{answer}
      It can be of any size greater than or equal to one.
      To have a transformation that is nilpotent of index four,
      whose cube has rangespace of dimension~$k$, take a vector space,
      a basis for that space, and a transformation that acts on that basis
      in this way.
      \begin{equation*}
         \begin{strings}{ccccccccc}
            \vec{\beta}_1 &\mapsto &\vec{\beta}_2 &\mapsto &\vec{\beta}_3
              &\mapsto &\vec{\beta}_4 &\mapsto &\zero  \\
            \vec{\beta}_5 &\mapsto &\vec{\beta}_6 &\mapsto &\vec{\beta}_7
              &\mapsto &\vec{\beta}_8 &\mapsto &\zero  \\
            &\vdotswithin{\vec{\beta}_{4k-3}}                       \\
            \vec{\beta}_{4k-3} &\mapsto &\vec{\beta}_{4k-2} 
              &\mapsto &\vec{\beta}_{4k-1}
              &\mapsto &\vec{\beta}_{4k} &\mapsto &\zero  \\
            &\vdotswithin{\vec{\beta}_{4k-3}}              \\
            \multicolumn{8}{l}{%
              \text{\textit{--possibly other, shorter, strings--}}}
         \end{strings}
      \end{equation*}
      So the dimension of the rangespace of $T^3$ can be as large as desired.
      The smallest that it can be is one\Dash there 
      must be at least one string or else the map's index of nilpotency 
      would not be four.  
    \end{answer}
  \item 
    Recall that similar matrices have the same eigenvalues.
    Show that the converse does not hold.
    \begin{answer}
      These two have only zero for eigenvalues
      \begin{equation*}
        \begin{mat}
          0  &0  \\
          0  &0
        \end{mat}
        \qquad
        \begin{mat}
          0  &0  \\
          1  &0
        \end{mat}
      \end{equation*}
      but are not similar (they have different canonical
      representatives, namely, themselves).  
    \end{answer}
  \item 
    Prove a nilpotent matrix is similar to one that is all zeros
    except for blocks of super-diagonal ones.
    \begin{answer}
      A simple reordering of the string basis will do.
      For instance, a map that is assoicated with this string basis
      \begin{equation*}
         \begin{strings}{ccccccc}
            \vec{\beta}_1 &\mapsto &\vec{\beta}_2 &\mapsto &\zero  
         \end{strings}
      \end{equation*}
      is represented with respect to 
      $B=\sequence{\vec{\beta}_1,\vec{\beta}_2}$ by this matrix
      \begin{equation*}
        \begin{mat}
          0  &0  \\
          1  &0          
        \end{mat}
      \end{equation*}
      but is represented with respect to 
      $B=\sequence{\vec{\beta}_2,\vec{\beta}_1}$ in this way.
      \begin{equation*}
        \begin{mat}
          0  &1  \\
          0  &0          
        \end{mat}
      \end{equation*}
    \end{answer}
  \recommended \item
    Prove that if a transformation has the same rangespace as nullspace.
    then the dimension of its domain is even.
    \begin{answer}
      Let $\map{t}{V}{V}$ be the transformation.
      If \( \rank (t)=\nullity (t) \) then the equation
      \( \rank(t)+\nullity(t)=\dim (V) \) shows that 
      \( \dim (V) \) is even.  
    \end{answer}
  \item 
    Prove that if two nilpotent matrices commute then their product and
    sum are also nilpotent.
    \begin{answer}
      For the matrices to be nilpotent they must be square.
      For them to commute they must be the same size.
      Thus their product and sum are defined.

      Call the matrices \( A \) and \( B \).
      To see that \( AB \) is nilpotent, multiply
      $
         (AB)^2=ABAB=AABB=A^2B^2$,
      and
         $(AB)^3=A^3B^3$, etc.,
      and, as \( A \) is nilpotent, that product is eventually zero.

      The sum is similar; use the Binomial Theorem.  
     \end{answer}
  \item 
    Consider the transformation of \( \matspace_{\nbyn{n}} \) given
    by \( t_S(T)=ST-TS \) where \( S \) is an \( \nbyn{n} \) matrix.
    Prove that if \( S \) is nilpotent then so is \( t_S \).
    \begin{answer}
      Some experimentation gives the idea for the proof.
      Expansion of the second power
      \begin{equation*}
        t^2_S(T)=S(ST-TS)-(ST-TS)S=S^2-2STS+TS^2
      \end{equation*}
      the third power
      \begin{align*}
        t^3_S(T)
          &=S(S^2-2STS+TS^2)-(S^2-2STS+TS^2)S  \\
          &=S^3T-3S^2TS+3STS^2-TS^3
      \end{align*}
      and the fourth power
      \begin{align*}
        t^4_S(T)
          &=S(S^3T-3S^2TS+3STS^2-TS^3)-(S^3T-3S^2TS+3STS^2-TS^3)S  \\
          &=S^4T-4S^3TS+6S^2TS^2-4STS^3+TS^4
      \end{align*}
      suggest that the expansions follow the Binomial Theorem.
      Verifying this by induction on the power of $t_S$ is routine.
      This answers the question because, where the index of nilpotency of 
      $S$ is $k$, in the expansion of $t^{2k}_S$  
      \begin{equation*}
        t^{2k}_S(T)=\sum_{0\leq i\leq 2k}(-1)^i\binom{2k}{i} S^iTS^{2k-i}
      \end{equation*}
      for any $i$ at least one of the $S^i$ and $S^{2k-i}$ 
      has a power higher than $k$, and so the term gives the zero matrix. 
    \end{answer}
  \item 
    Show that if \( N \) is nilpotent then \( I-N \) is
    invertible.
    Is that `only if' also?
    \begin{answer}
      Use the geometric series:
      $
         I-N^{k+1}=(I-N)(N^k+N^{k-1}+\cdots+I)
      $.
      If \( N^{k+1} \) is the zero matrix then we have a right inverse for
      \( I-N \).
      It is also a left inverse.

      This statement is not `only if' since
      \begin{equation*}
         \begin{mat}[r]
            1  &0  \\
            0  &1
         \end{mat}
         -\begin{mat}[r]
            -1  &0  \\
            0  &-1
         \end{mat}
      \end{equation*}
      is invertible.  
     \end{answer}
%  \recommended \item 
%    Show that when a nilpotent matrix \( T \) is in canonical form 
%    then the number of
%    blocks of \( \nbyn{(k+1)} \) matrices that are all zeros
%    except for subdiagonal ones is
%    \( 2\,(\nullity (T^k))
%      -\nullity (T^{k+1})-\nullity (T^{k-1}) \).
\index{nilpotent|)}
\end{exercises}
