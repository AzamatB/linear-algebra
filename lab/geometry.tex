\chapter{Geometry of Linear Maps}

\Sage{} can illustrate the geometric effect of linear maps.
Here we focus on transformations of the plane~$\Re^2$.  




%========================================
\section{Lines map to lines}
The pictures in this chapter are 
based on the observation that under a linear map, the image of a line
in the domain is a line in the range.

We first verify that.
Consider a domain space~$\Re^d$ and codomain space~$\Re^c$, along with
the linear map~$h$.
We get a line in the domain by fixing a vector of slopes~$\vec{m}\in\Re^d$
and a vector of offsets from the origin~$\vec{b}\in\Re^d$, 
and then considering the set 
$\ell = \set{\vec{v}=\vec{m}\cdot s +\vec{b}\suchthat s\in\Re}$.
The image of~$\ell$ is the set 
$h(\ell)=\set{h(\vec{m}\cdot s+\vec{b})\suchthat s\in\Re}
=\set{h(\vec{m})\cdot s+h(\vec{b})\suchthat s\in\Re}$.
This is a line in the codomain~$\Re^c$ with the vector of 
slopes~$h(\vec{m})$ and the vector of offsets~$h(\vec{b})$. 

For example, consider the transformation $\map{t}{\Re^2}{\Re^2}$ 
that rotates vectors counterclockwise by $\pi/6$~radians.
\begin{equation*}
  \rep{t}{\stdbasis_2,\stdbasis_2}
  =
  \begin{mat}
    \cos(\pi/6)  &\sin(\pi/6) \\
    -\sin(\pi/6)  &\cos(\pi/6)
  \end{mat}
  = 
  \begin{mat}
    \sqrt{3}/2   &1/2 \\
    -1/2          &\sqrt{3}/2
  \end{mat}
\end{equation*}
Also consider the line $y=3x+2$, described here as a set of vectors.
\begin{equation*}
  \ell=\set{\colvec{x \\ y}=\colvec{3 \\ 1}\cdot s+\colvec{2 \\ 0}\suchthat s\in\Re}
\end{equation*}
That line when rotated by~$t$ is this set.
\begin{equation*}
  t(\ell)
  =
  \set{\colvec{x \\ y}=\frac{1}{2}\colvec{3\sqrt{3}-1 \\ 3+\sqrt{3}}\cdot s
                                  +\colvec{\sqrt{3} \\ 1}\suchthat s\in\Re}
\end{equation*}
\begin{sageoutput}
s = var('s')
plot.options['figsize'] = 2.5
plot.options['axes_pad'] = 0.05
plot.options['fontsize'] = 7
plot.options['dpi'] = 500
plot.options['aspect_ratio'] = 1
ell = parametric_plot((3*s+2,1*s), (s, -10, 10))
ell.set_axes_range(-4, 4, -4, 4)
ell.save("sageoutput/plot_action0.png", fontsize=7)
t_x(s) = ((3*sqrt(3)-1)/2)*s+sqrt(3)
t_y(s) = ((3+sqrt(3))/2)*s+1
t_ell = parametric_plot((t_x(s), t_y(s)), (s, -10, 10))
t_ell.set_axes_range(-4, 4, -4, 4)
t_ell.save("sageoutput/plot_action0a.png", fontsize=7)
\end{sageoutput}
\begin{equation*}
  \vcenteredhbox{\includegraphics{sageoutput/plot_action0.png}}
  \quad\mapsvia{t}\quad
  \vcenteredhbox{\includegraphics{sageoutput/plot_action0a.png}}
\end{equation*}
(The limits of $10$ and~$-10$ on the parameter~$s$ are arbitrary, just
chosen to be large enough that the line segment covers the entire 
domain and codomain intervals shown, from $-4$ to~$4$.)

So lines map to lines.
\begin{equation*}
\set{\vec{v}=\vec{m}\cdot s +\vec{b}\suchthat s\in\Re}
\quad\longrightarrow\quad
\set{h(\vec{m})\cdot s+h(\vec{b})\suchthat s\in\Re}  
\end{equation*}
We'll note also that lines through the origin map to lines
through the origin:
if $\vec{b}=\zero$ then 
$h(\vec{b})$ is $\zero$, since any linear map sends the zero vector
in the domain to the zero vector in the codomain. 




%========================================
\section{The unit square}
We first illustrate the effect of transformations 
$\map{t}{\Re^2}{\Re^2}$ 
by applying them to
this unit square.
\begin{center}
  \includegraphics{sageoutput/plot_action1.png}
\end{center}
That picture was generated by this \Sage{} code.
\begin{sageoutput}
load "plot_action.sage"
p = plot_square_action(1,0,0,1) 
p.set_axes_range(-0.5, 1.5, -0.5, 1.5) 
p.save("sageoutput/plot_action1.png")
\end{sageoutput}
\noindent The \inlinecode{plot_square_action(a, b, c, d)} call
shows the effect on the square of this matrix.
\begin{equation*}
  \rep{t}{\stdbasis_2,\stdbasis_2}=
  \begin{mat}
    a &b \\
    c &d
  \end{mat}
\end{equation*}
The \Sage{} code above uses
the identity matrix so it plots the square unchanged.

The code for \inlinecode{plot_square_action} is at the end of this chapter
but it is easy with the observation above 
that linear maps send lines to lines.
The routine finds the effect of the map 
\begin{equation*}
  \rowvec{x &y}
  \begin{mat}
    a &b  \\
    c &d
  \end{mat}
\end{equation*}
on the four corners of the square 
\begin{equation*}
  \colvec{0 \\ 0}\mapsunder{t}\colvec{0 \\ 0}\quad
  \colvec{1 \\ 0}\mapsunder{t}\colvec{a \\ b}\quad
  \colvec{1 \\ 1}\mapsunder{t}\colvec{a+c \\ b+d}\quad
  \colvec{0 \\ 1}\mapsunder{t}\colvec{c \\ d}
\end{equation*}
and plots four line segments.

For example, this code
\begin{sageoutput}
load "plot_action.sage"
q = plot_square_action(1,0,0,1) 
q.set_axes_range(-6, 6, -1, 6) 
q.save("sageoutput/plot_action2.png")
p = plot_square_action(1,2,3,4) 
p.set_axes_range(-6, 6, -1, 6) 
p.save("sageoutput/plot_action2a.png")
\end{sageoutput}
\noindent generates these two pictures showing the effect of the 
matrix.\footnote{The remaining examples in this chapter omit the 
fiddly lines that load, save, set the axis ranges, etc.}
\begin{equation*}
  \vcenteredhbox{\includegraphics{sageoutput/plot_action2.png}}
  \quad\mapsunder{\big (\begin{smallmatrix} 1 &2 \\ 3 &4 \end{smallmatrix}\big )}\quad
  \vcenteredhbox{\includegraphics{sageoutput/plot_action2a.png}}
\end{equation*}
The colors are there to show that transformations can change
orientations.
Suppose that we take the colors in their natural order of red, orange, 
green, and blue.
Then the domain square is a counterclockwise shape, while the transformed
square is clockwise.


\subsection{Factoring matrices}
Recall that the row operations of Gauss's Method can be done with
matrix multiplication.
For instance, multiplication from the left by this matrix has the effect of the
row operation $2\rho_1+\rho_2$.
\begin{equation*}
  \begin{mat}
    1 &0 &0 \\
    2 &1 &0 \\
    0 &0 &1
  \end{mat}
  \begin{mat}
    3 &1 &4 \\
   -6 &1 &-8 \\
    0 &-3 &2
  \end{mat}
  =
  \begin{mat}
    3 &1  &4 \\ 
    0 &3 &0 \\
    0 &-3  &2
  \end{mat}
\end{equation*}
Thus, assuming that we don't need any row swaps, we can follow the 
Gauss's Method steps to bring a matrix to echelon form with a sequence of left 
multiplications.
Here we tack on an additional matrix to perform $-\rho_2+\rho_3$
and produce echelon form.
\begin{equation*}
  \begin{mat}
    1 &0  &0 \\
    0 &1  &0 \\
    0 &-1 &1
  \end{mat}
  \begin{mat}
    1 &0 &0 \\
    2 &1 &0 \\
    0 &0 &1
  \end{mat}
  \begin{mat}
    3 &1 &4 \\
   -6 &1 &-8 \\
    0 &-3 &2
  \end{mat}
  =
  \begin{mat}
    3 &1  &4 \\ 
    0 &3  &0 \\
    0 &0  &2
  \end{mat}
  \tag{$*$}
\end{equation*}

When the book first covered Gauss's method, the operations involved 
using a row to work on a row below it.
Matrices that perform those operations are \textit{lower triangular}
since all of their nonzero entries are in the lower left.
Matrices with all of their nonzero entries in the upper right are 
\textit{upper triangular}.
The echelon form 
matrix in ($*$)~above is upper triangular. 
 
We can perform column operations that are just like the row operations
to eliminate entries in the above matrix.
Here we take $-1/3$ times the first column and add to the second column.
\begin{equation*}
  \begin{mat}
    3 &1  &4 \\ 
    0 &3  &0 \\
    0 &0  &2
  \end{mat}
  \begin{mat}
    1  &-1/3  &0  \\
    0  &1     &0  \\
    0  &0     &1
  \end{mat}
  =
  \begin{mat}
    3 &0  &4 \\ 
    0 &3  &0 \\
    0 &0  &2
  \end{mat}
\end{equation*}
We now add $-4/3$~times the first column to the third column,
to finish with a diagonal matrix.
\begin{equation*}
  \begin{mat}
    3 &1  &4 \\ 
    0 &3  &0 \\
    0 &0  &2
  \end{mat}
  \begin{mat}
    1  &0     &-4/3  \\
    0  &1     &0  \\
    0  &0     &1
  \end{mat}
  =
  \begin{mat}
    3 &0  &0 \\ 
    0 &3  &0 \\
    0 &0  &2
  \end{mat}
\end{equation*}
Thus, where there are no swaps needed, we can write this equation involving
matrices.
\begin{equation*}
  L_1L_2\cdots L_k\cdot A\cdot U_1U_2\cdot U_r = D
\end{equation*}
where $D$ is diagonal, the $L_i$ are lower-triangular row operation matrices,
and the $U_j$ are upper-tirangular column operation matrices. 

Now, we are interested in transformations of real space so we assume all
matrices are square.
All of the row operations can be undone (for instance, $2\rho_1+\rho_2$
is undone with $-2\rho_1+\rho_2$), so each of those lower triangular matrices
has a lower-triangular inverse.
$A\cdot U_1U_2\cdots U_r = L_k^{-1}\cdots L_1^{-1}D$. 
Likewise, each of the upper-triangular matrices has an inverse and it is
upper-triangular.
Hence, if no swaps are required in Gauss's Method reduction of $A$ then we have
this factorization 
$A = L_k^{-1}\cdots L_1^{-1}\cdot D\cdot U_r^{-1}\cdots U_1^{-1}$.
To ensure that no swaps are required we can pre-swap with a permutation matrix.
\begin{equation*}
  P\cdot A = L_k^{-1}\cdots L_1^{-1}\cdot D\cdot U_r^{-1}\cdots U_1^{-1}
  \tag{$**$}
\end{equation*}
The product of the $L$'s is lower-triangular and the product of the
$U$'s is upper-triangular so this result is often known as $PA=LDU$.
However, we'll leave the $L$'s and $U$'s uncombined.

Recall that any matrix $T$ factors as $H=PBQ$, 
where $P$ and $Q$ are nonsingular and $B$ is a partial-identity matrix.
Recall also that nonsingular matrices
factor into elementary matrices
$PBQ=T_nT_{n-1}\cdots T_jBT_{j-1}\cdots T_1$,
which are matrices that
come from the identity $I$ after one Gaussian step
\begin{equation*}
  I\grstep{k\rho_i}M_i(k) 
  \qquad 
  I\grstep{\rho_i\leftrightarrow\rho_j}P_{i,j}  
  \qquad
  I\grstep{k\rho_i+\rho_j}C_{i,j}(k) 
\end{equation*}
for $i\neq j$, $k\neq 0$.
So if we understand the effect of a linear map described
by a partial-identity matrix and the effect of the linear maps
described by the elementary matrices then we will in some sense
understand the effect of any linear map.
(To understand them we mean to give a description of their geometric effect;
the pictures below stick to transformations of $\Re^2$ for ease of drawing
but the principles extend for maps from any $\Re^n$ to any $\Re^m$.)







\section{Maps preserve lines through the origin}





\lstinputlisting{plot_action.sage}

\begin{center}
  \includegraphics{sageoutput/plot_action1.png}
\end{center}

\endinput


TODO:
