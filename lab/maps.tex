\chapter{Maps}\label{chapter:maps}


We've used \Sage{} to define vector spaces.
Next we explore operations that we can do on vector spaces.
  

%========================================
\section{Left/right}
\Sage{} represents linear
maps differently than the book does.
Rather than quarrel with the tool, below we will do it
\Sage's way.

Consider the application of a linear map 
to a member of a vector space
$t(\vec{v})$.
For example, 
with this function $\map{t}{\Re^2}{\Re^3}$ and this element of the domain
\begin{equation*}
  t(\colvec{a \\ b})
  =\colvec{a+b \\ a-b \\ b}
  \qquad
  \vec{v}=\colvec{1 \\ 3}
\end{equation*}
the map application gives this.
\begin{equation*}
  t(\colvec{1 \\ 3})
  =\colvec{4 \\ -2 \\ 3}
\end{equation*}

To represent the map application we first fix bases. 
In this example
we use the canonical bases $\stdbasis_2\subset\Re^2$ 
and~$\stdbasis_3\subset\Re^3$.
Then with respect to the bases the book finds  
a matrix~$T=\rep{t}{\stdbasis_2,\stdbasis_3}$ 
and a column vector $\vec{w}=\rep{\vec{v}}{\stdbasis_2}$,
and represents $t(\vec{v})$ 
with the product $T\vec{w}$.
\begin{equation*}
  \begin{mat}
    1 &1 \\
    1 &-1 \\
    0 &1
  \end{mat}
  \colvec{1 \\ 3}
  =
  \colvec{4 \\ -2 \\ 3}
\end{equation*}
That is, the book is write right: its notation puts the vector on the right 
of the matrix.

However, this choice is a matter of taste and many authors instead
use a row vector that multiplies a matrix from the left.
\Sage{} is in this camp and
represents the map application in this way.
\begin{equation*}
  \rowvec{1 &3}
  \begin{mat}
    1 &1  &0 \\
    1 &-1 &1
  \end{mat}
  =
  \rowvec{4 &-2 &3}
\end{equation*}
Obviously the difference is cosmetic but can cause confusion.
The translation is that, compared to the book's representation $T\vec{w}$,
\Sage{} prefers the transpose
$\trans{(T\vec{w})}=\trans{\vec{w}}\;\trans{T}$.



  

%========================================
\section{Defining}
We will see two different ways to define a linear transformation.

\subsection{Symbolically}
We first define a map that takes two inputs and returns three outputs.
\begin{sageoutput}
a, b = var('a, b')   
T_symbolic(a, b) = [a+b, a-b, b]         
T_symbolic       
\end{sageoutput}
We have not yet defined a domain and codomain 
so this not a function\Dash instead it is a prototype for a function.
Make an instance of a function by applying $T_{\textit{symbolic}}$ on a 
particular domain and codomain.
\begin{sageoutput}[d,0,2;s,7,68,62;s,8,70,62]
a, b = var('a, b')   
T_symbolic(a, b) = [a+b, a-b, b]         
T = linear_transformation(RR^2, RR^3, T_symbolic)
T                                              
\end{sageoutput}
\noindent Note the left/right issue again: \Sage's matrix is the transpose of
the matrix that the book would use.

Evaluating this function on a member of the domain gives a member
of the codomain. 
\begin{sageoutput}[d,0,3]
a, b = var('a, b')   
T_symbolic(a, b) = [a+b, a-b, b]         
T = linear_transformation(RR^2, RR^3, T_symbolic)
v = vector(RR, [1, 3])  
T(v)
\end{sageoutput}
% \begin{lstlisting}
% sage: v = vector(RR, [1, 3])  
% sage: T(v)
% (4.00000000000000, -2.00000000000000, 3.00000000000000)
% \end{lstlisting}

\Sage{} can compute the interesting things about the transformation.
Here it finds the null space 
and range space, using the equivalent 
terms \textit{kernel} and \textit{image}.
\begin{sageoutput}[d,0,3;s,4,70,59;s,8,70,59]
a, b = var('a, b')   
T_symbolic(a, b) = [a+b, a-b, b]         
T = linear_transformation(RR^2, RR^3, T_symbolic)
T.kernel()                                       
T.image()                                        
\end{sageoutput}
% \begin{lstlisting}
% sage: T.kernel()                                       
% Vector space of degree 2 and dimension 0 over Real Field with 53 bits 
%     of precision
% Basis matrix:
% []
% sage: T.image()                                        
% Vector space of degree 3 and dimension 2 over Real Field with 53 bits 
%     of precision
% Basis matrix:
% [  1.00000000000000  0.000000000000000  0.500000000000000]
% [ 0.000000000000000   1.00000000000000 -0.500000000000000]
% \end{lstlisting}
The null space's basis is empty because 
it is the trivial subspace of the domain,
with dimension~$0$.
Therefore $T$ is one-to-one.

The range space has a $2$-vector basis. 
This agrees with the theorem that
the dimension of the null space plus the dimension of the 
range space equals to the dimension of the domain.

For contrast consider a map that is not one-to-one.
\begin{sageoutput}[s,8,68,62;s,9,70,62]
S_symbolic(a, b) = [a+2*b, a+2*b]
S_symbolic
S = linear_transformation(RR^2, RR^2, S_symbolic)
S
v = vector(RR, [1, 3])  
S(v)
\end{sageoutput}
% \begin{lstlisting}
% sage: S_symbolic(a, b) = [a+2*b, a+2*b]
% sage: S_symbolic
% (a, b) |--> (a + 2*b, a + 2*b)
% sage: S = linear_transformation(RR^2, RR^2, S_symbolic)
% sage: S
% Vector space morphism represented by the matrix:
% [1.00000000000000 1.00000000000000]
% [2.00000000000000 2.00000000000000]
% Domain: Vector space of dimension 2 over Real Field with 53 bits of 
%     precision
% Codomain: Vector space of dimension 2 over Real Field with 53 bits of 
%     precision
% sage: S(v)
% (7.00000000000000, 7.00000000000000)
% \end{lstlisting}
\noindent This map is not one-to-one since the input $(a,b)=(2,0)$  gives
the same result as~$(a,b)=(0,1)$.  
\begin{sageoutput}[d,0,2;s,3,69,58;s,7,70,59]
S_symbolic(a, b) = [a+2*b, a+2*b]
S = linear_transformation(RR^2, RR^2, S_symbolic)
S.kernel()
S.image()
\end{sageoutput}
% \begin{lstlisting}
% sage: S.kernel()
% Vector space of degree 2 and dimension 1 over Real Field with 53 bits 
%     of precision
% Basis matrix:
% [  1.00000000000000 -0.500000000000000]
% sage: S.image()
% Vector space of degree 2 and dimension 1 over Real Field with 53 bits 
%     of precision
% Basis matrix:
% [1.00000000000000 1.00000000000000]  
% \end{lstlisting}
The null space has nonzero dimension, namely it 
has dimension~$1$,
so \Sage{} agrees that the map is not one-to-one.

Without looking at the range space we know that its dimension must be~$1$ 
because the dimensions of the null and range spaces add to
the dimension of the domain.
Again, \Sage{} confirms our calculation.



\subsection{Via matrices}
We can define a transformation by specifying 
the matrix representing its action.
\begin{sageoutput}[s,7,68,62;s,8,69,61]
M = matrix(RR, [[1, 2], [3, 4], [5, 6]])
m = linear_transformation(M)
m  
\end{sageoutput}
\noindent Note again that \Sage{} prefers the 
representation where the vector multiplies
from the left.
\begin{sageoutput}[d,0,2]
M = matrix(RR, [[1, 2], [3, 4], [5, 6]])
m = linear_transformation(M)
v = vector(RR, [7, 8, 9])
m(v)  
\end{sageoutput}
\noindent \Sage{} has done this calculation.
\begin{equation*}
  \colvec{7 &8 &9}
  \begin{mat}
    1 &2 \\
    3 &4 \\
    5 &6
  \end{mat}
  =\colvec{76 &100}
\end{equation*}

If you have a matrix intended for a vector-on-the-right
calculation (as in the book) then \Sage{} will make the necessary adaptation.
\begin{sageoutput}[s,7,68,62;s,8,70,62]
N = matrix(RR, [[1, 3, 5], [2, 4, 6]])
n = linear_transformation(N, side='right')
n
v = vector(RR, [7, 8, 9])
n(v)  
\end{sageoutput}
% \begin{lstlisting}
% sage: A = matrix(RR, [[1, 2], [3, 4]])
% sage: A
% [1.00000000000000 2.00000000000000]
% [3.00000000000000 4.00000000000000]
% sage: F = linear_transformation(RR^2, RR^2, A, side='right')
% sage: F
% Vector space morphism represented by the matrix:
% [1.00000000000000 3.00000000000000]
% [2.00000000000000 4.00000000000000]
% Domain: Vector space of dimension 2 over Real Field with 53 bits of 
%     precision
% Codomain: Vector space of dimension 2 over Real Field with 53 bits of 
%     precision
% \end{lstlisting}
\noindent Although we gave it a \inlinecode{side='right'} option, 
the matrix that \Sage{} shows by default is for 
\inlinecode{side='left'}.

Despite that we specified them differently, 
these two transformations are the same.
\begin{sageoutput}[d,0,4]
M = matrix(RR, [[1, 2], [3, 4], [5, 6]])
m = linear_transformation(M)
N = matrix(RR, [[1, 3, 5], [2, 4, 6]])
n = linear_transformation(N, side='right')
m == n  
\end{sageoutput}

We can ask the same questions of linear transformations created from
matrices that we asked of linear transformations created from functions.
\begin{sageoutput}[d,0,2;s,3,70,59]
M = matrix(RR, [[1, 2], [3, 4], [5, 6]])
m = linear_transformation(M)
m.kernel() 
\end{sageoutput}
\noindent The null space of $m$ is not the trivial subspace of $\Re^3$ 
and so this function is not one-to-one.
The domain has dimension~$3$ and the null space has dimension~$1$ 
and so the
range space is a dimension~$2$ subspace of $\Re^2$.
\begin{sageoutput}[d,0,2;s,3,70,59] 
M = matrix(RR, [[1, 2], [3, 4], [5, 6]])
m = linear_transformation(M)
m.image()
m.image() == RR^2
\end{sageoutput}
\noindent \Sage{} lets us have the matrix represent a transformation involving 
spaces with nonstandard bases.
\begin{sageoutput}
M = matrix(RR, [[1, 2], [3, 4]])
domain_basis = [vector(RR, [1, -1]), vector(RR, [1, 1])]
D = (RR^2).subspace_with_basis(domain_basis)
codomain_basis = [vector(RR, [2, 0]), vector(RR, [0, 3])]
C = (RR^2).subspace_with_basis(codomain_basis)
m = linear_transformation(D, C, M)
m(vector(RR, [1, 0]))
\end{sageoutput}
\Sage{} has calculated that
\begin{equation*}
  \colvec{1 \\ 0}=(1/2)\colvec{1 \\ -1}+(1/2)\colvec{1 \\ 1}
  \quad\text{so}\quad
  \rep{\colvec{1 \\ 0}}{\textit{domain\_basis}}=\colvec{1/2 \\ 1/2} 
\end{equation*}
and then computed this.
\begin{equation*}
  \rep{m(\vec{v})}{\textit{codomain\_basis}}
  =
  \rowvec{1/2 &1/2}
  \begin{mat}
    1 &2 \\
    3 &4
  \end{mat}
  =
  \rowvec{2 &3}
  \quad\text{so}\quad
  m(\vec{v})=2\colvec{2 \\ 0}+3\colvec{0 \\ 3}
  =\colvec{4 \\ 9}
\end{equation*}





%========================================
\section{Operations}

Consider the set of linear maps from some 
Fix some vector space domain~$D$ and codomain~$C$ and consider the
set of all linear transformations between them. 
This set has some natural operations, including
addition and scalar multiplication.
\Sage{} can work with those operations.

\subsection{Addition}
% First create two functions. 
% \begin{sageoutput}
% f_symbolic(x,y) = [x-y, x+2*y, 3*x]  
% g_symbolic(x,y) = [y, 2*x-y, y]  
% \end{sageoutput}
% We can add these two and with that new function make a linear 
% transformation.
% \begin{sageoutput}[d,0,2;s,9,68,62;s,10,70,62]
% f_symbolic(x,y) = [x-y, x+2*y, 3*x]  
% g_symbolic(x,y) = [y, 2*x-y, y]  
% f_symbolic+g_symbolic
% h = linear_transformation(RR^2, RR^3, f_symbolic+g_symbolic)
% h
% \end{sageoutput}
% We could instead make two linear transformations and then add.
% \begin{sageoutput}[d,0,2;s,9,68,62;s,10,70,62]
% f_symbolic(x,y) = [x-y, x+2*y, 3*x]  
% g_symbolic(x,y) = [y, 2*x-y, y]  
% f = linear_transformation(RR^2, RR^3, f_symbolic)
% g = linear_transformation(RR^2, RR^3, g_symbolic)
% h = f + g
% h
% \end{sageoutput}
Recall that matrix addition is defined so that the representation of
the sum of two linear transformations is the matrix sum of the representatives.
\Sage{} can illustrate.
\begin{sageoutput}[s,6,68,62;s,7,70,62;s,14,68,62;s,15,70,62;s,20,68,62;s,21,70,62]
M = matrix(RR, [[1, 2], [3, 4]])
m = linear_transformation(RR^2, RR^2, M)
m
N = matrix(RR, [[5, -1], [0, 7]])
n = linear_transformation(RR^2, RR^2, N)
n
m+n
M+N
\end{sageoutput}
\noindent Similarly, linear map scalar multiplication is reflected by 
matrix scalar multiplication.
\begin{sageoutput}[d,0,2;s,6,68,62;s,7,70,62]
M = matrix(RR, [[1, 2], [3, 4]])
m = linear_transformation(RR^2, RR^2, M)
m*3
M*3  
\end{sageoutput}



\subsection{Composition}
The composition of linear maps gives rise to matrix multiplication.
\Sage{} uses the star \inlinecode{*} to denote composition of linear maps.
\begin{sageoutput}[s,6,68,62;s,7,70,62;s,14,68,62;s,15,70,62;s,26,68,62;s,27,70,62]
M = matrix(RR, [[1, 2], [3, 4]])
m = linear_transformation(RR^2, RR^2, M)
m
N = matrix(RR, [[5, -1], [0, 7]])
n = linear_transformation(RR^2, RR^2, N)
n
M*N
N*M
m*n
\end{sageoutput}
Note the left/right issue.
Remember that $\composed{m}{n}$ is the map $\vec{v}\mapsto m(n(\vec{v}))$, 
so that $n$ is applied first. 
\Sage{} puts the representing vector on the left, so 
$N$ must come left-most: $\vec{w}\;N\cdot M=\vec{w}(NM)$.

\endinput


TODO:
