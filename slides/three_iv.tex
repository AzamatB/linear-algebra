% see: https://groups.google.com/forum/?fromgroups#!topic/comp.text.tex/s6z9Ult_zds
\makeatletter\let\ifGm@compatii\relax\makeatother 
\documentclass[10pt,t,serif,professionalfont]{beamer}
\PassOptionsToPackage{pdfpagemode=FullScreen}{hyperref}
\PassOptionsToPackage{usenames,dvipsnames}{color}
% \DeclareGraphicsRule{*}{mps}{*}{}
\usepackage{../linalgjh}
\usepackage{present}
\usepackage{xr}\externaldocument{../map4} % read refs from .aux file
\usepackage{catchfilebetweentags}
\usepackage{etoolbox} % from http://tex.stackexchange.com/questions/40699/input-only-part-of-a-file-using-catchfilebetweentags-package
\makeatletter
\patchcmd{\CatchFBT@Fin@l}{\endlinechar\m@ne}{}
  {}{\typeout{Unsuccessful patch!}}
\makeatother

\mode<presentation>
{
  \usetheme{boxes}
  \setbeamercovered{invisible}
  \setbeamertemplate{navigation symbols}{} 
}
\addheadbox{filler}{\ }  % create extra space at top of slide 
\hypersetup{colorlinks=true,linkcolor=blue} 

\title[Matrix Operations] % (optional, use only with long paper titles)
{Three.IV Matrix Operations}

\author{\textit{Linear Algebra} \\ {\small Jim Hef{}feron}}
\institute{
  \texttt{http://joshua.smcvt.edu/linearalgebra}
}
\date{}


\subject{Matrix Operations}
% This is only inserted into the PDF information catalog. Can be left
% out. 

\begin{document}
\begin{frame}
  \titlepage
\end{frame}

% =============================================
% \begin{frame}{Reduced Echelon Form} 
% \end{frame}



% ..... Three.IV.1 .....
\section{Sums and Scalar Products}
%..........
\begin{frame}{Representing operations on linear functions}
Recall the operations on linear functions of scalar multiplication
and addition defined by: for  
$\map{f,g}{V}{W}$, where $r\in\Re$
the scalar multiple $r\cdot f$ function does this
\begin{equation*}
  \vec{v}\mapsunder{r\cdot f} r\cdot (f(\vec{v}))
\end{equation*}
and the sum of the two functions does this.
\begin{equation*}
  \vec{v}\mapsunder{f+g} f(\vec{v})+g(\vec{v})
\end{equation*}
Here we will see how the matrix representations $\rep{f}{B,D}$ and 
$\rep{g}{B,D}$
combine to give $\rep{r\cdot f}{B,D}$
and $\rep{f+g}{B,D}$.

\pause
\ex
Suppose that $\map{f}{V}{W}$ is the linear map represented with respect to 
some bases~$B,D$ by this matrix.
\begin{equation*}
  F=
  \rep{f}{B,D}=
  \begin{mat}
    2  &1  \\
    3  &4  
  \end{mat}
\end{equation*}
We will find the matrix representing the function $5f$.
That is, we will show how to produce the matrix representation of $5f$
from the matrix representation~F of~$f$. 
\end{frame}
\begin{frame}
Consider representations of vectors from the domain and codomain.
\begin{equation*}
  \rep{\vec{v}}{B}=\colvec{v_1 \\ v_2}
  \quad
  \rep{\vec{w}}{D}=\colvec{w_1 \\ w_2}
  % =\colvec{2v_1+v_2 \\ 3v_1+4v_2} 
\end{equation*}
\pause
Since $5\vec{w}=5\cdot(w_1\vec{\delta}_1+w_2\vec{\delta}_2)
=5w_1\vec{\delta}_1+5w_2\vec{\delta}_2$,
application of the function $\map{5f}{V}{W}$
yields this representation of the codomain vector.
\begin{equation*}
  \rep{5f(\vec{v})}{D}
  =\rep{5\vec{w}}{D}=\colvec{5w_1 \\ 5w_2} 
\end{equation*}
So moving from the function $f$ to the function~$5f$
has the effect on the representations of vectors that it
transforms the codomain vector by multipling each entry by $5$.
\end{frame}
\begin{frame}
In this example the action of the function is represented as here.  
\begin{equation*}\
  \rep{f}{B,D}\cdot \rep{\vec{v}}{B}=
  \begin{mat}
    2  &1 \\
    3  &4
  \end{mat}
  \colvec{v_1 \\ v_2}
  =\colvec{2v_1+v_2 \\ 3v_1+4v_2}
\end{equation*}
\pause
We want the matrix 
that makes this 
true.
\begin{equation*}
  \rep{5f}{B,D}\cdot
  \colvec{v_1 \\ v_2}
  =\colvec{5(2v_1+v_2) \\ 5(3v_1+4v_2)}
  =\colvec{10v_1+5v_2 \\  15v_1+20v_2}
\end{equation*}
Therefore, at least in this example
\begin{equation*}
  \rep{5f}{B,D}
  =
  \begin{mat}
    10 &5 \\
    15 &20
  \end{mat}
\end{equation*}
so going from the function $f$ to the 
function~$5f$ has the effect on the representation~$F$ of  
multiplying all the entries by $5$.
\end{frame}


\begin{frame}
\ex
Suppose that $\map{f,g}{V}{W}$ are linear maps represented with respect to 
some bases by these matrices.
\begin{equation*}
  F=
  \rep{f}{B,D}=
  \begin{mat}
    2  &1  \\
    3  &4  
  \end{mat}
  \qquad
  G=
  \rep{g}{B,D}=
  \begin{mat}
    5  &8  \\
    7  &6  
  \end{mat}
\end{equation*}
We want the matrix representing the function $f+g$.

\pause
If $f(\vec{v})=\vec{u}$ and $g(\vec{v})=\vec{w}$ then
$f+g$ does this.
\begin{align*}
  \vec{v}
  &\mapsunder{f+g}
  \vec{u}+\vec{v}                      \\
  &\qquad =u_1\vec{\delta}_1+u_2\vec{\delta}_2
  +
  w_1\vec{\delta}_1+w_2\vec{\delta}_2   \\
  &\qquad=(u_1+w_1)\vec{\delta}_1+(u_2+w_2)\vec{\delta}_2
\end{align*}
Thus for any $\vec{v}$, the effect on the representatives 
\begin{equation*}
  \rep{f(\vec{v})}{D}=\colvec{u_1 \\ u_2}
  \quad
  \rep{g(\vec{v})}{D}=\colvec{w_1 \\ w_2}
\end{equation*}
of adding the functions is to add the column vectors.
\begin{equation*}
  \rep{(f+g)\,(\vec{v})}{D}=\colvec{u_1+w_1 \\ u_2+w_2}
\end{equation*}
\end{frame}
\begin{frame}
The particular functions in this example have 
this action on the representations.
\begin{align*}
  \rep{f(\vec{v})}{D}=
  \begin{mat}
    2  &1  \\
    3  &4  
  \end{mat}
  \colvec{v_1 \\ v_2}
  =\colvec{2v_1+v_2 \\ 3v_1+4v_2}
  \\
  \rep{g(\vec{v})}{D}=
  \begin{mat}
    5  &8  \\
    7  &6  
  \end{mat}
  \colvec{v_1 \\ v_2}
  =\colvec{5v_1+8v_2 \\ 7v_1+6v_2}
\end{align*}
So we want the matrix with this effect.
\begin{equation*}
  \rep{(f+g)\,(\vec{v})}{D}
  \colvec{v_1 \\ v_2}
  =\colvec{7v_1+9v_2 \\ 10v_1+10v_2}
\end{equation*}
\pause
Thus
\begin{equation*}
  \rep{f+g}{B,D}=
  \begin{mat}
    7  &9  \\
    10  &10  
  \end{mat}
\end{equation*}
\pause
and at least in this example
the representation of the sum function is the entry-by-entry sum of the
representations of the two functions.  
\end{frame}

\begin{frame}{Definition of matrix sum and scalar multiple}
\df[def:SumScalarProdMats]
\ExecuteMetaData[../map4.tex]{df:SumScalarProdMats}

\pause
\ex
Where
\begin{equation*}
  A=
  \begin{mat}
    1  &-1 \\
    2  &3
  \end{mat}
  \quad
  B=
  \begin{mat}
    0  &0     &2  \\
    9  &-1/2  &5
  \end{mat}
  \quad
  C=
  \begin{mat}
    1  &0 \\
    8  &-1
  \end{mat}
\end{equation*}
Then
\begin{equation*}
  A+C=
  \begin{mat}
    2  &-1  \\
    10 &2
  \end{mat}
  \qquad
  5B=
  \begin{mat}
    0  &0    &10 \\
    45 &-5/2 &25 
  \end{mat}
\end{equation*}
Because the sizes don't match, none of these is defined: $A+B$, $B+A$, 
$B+C$, $C+B$.

\end{frame}




%..........
\begin{frame}
\th[th:MatOpsRepMapOps]
\ExecuteMetaData[../map4.tex]{th:MatOpsRepMapOps}

\pause
\pf
We can generalize the two examples that started this section.
See \nearbyexercise{exer:CorrspMapMatOps}.
\qed

\pause
\medskip
\df[df:ZeroMatrix]
\ExecuteMetaData[../map4.tex]{df:ZeroMatrix}

\pause
\medskip
\ex
The zero matrix is the identity element for matrix addition.
\begin{equation*}
  \begin{mat}
    3 &1 &2 \\
    5 &0 &9
  \end{mat}
  +
  \begin{mat}
    0 &0 &0 \\
    0 &0 &0
  \end{mat}
  =
  \begin{mat}
    3 &1 &2 \\
    5 &0 &9
  \end{mat}
\end{equation*}
This reflects the fact that a zero matrix represents a zero function
$\map{Z}{V}{W}$, which is the identity elements for
function addition. 
\end{frame}




% ..... Three.IV.2 .....
\section{Matrix Multiplication}
%..........
\begin{frame}
Besides scalar multiplication and addition, another operation that 
we can perform on functions is composition.

\pause
\lm[lm:CompositionOfLinearMapsIsLinear]
\ExecuteMetaData[../map4.tex]{lm:CompositionOfLinearMapsIsLinear}

\pause
\pf
\ExecuteMetaData[../map4.tex]{pf:CompositionOfLinearMapsIsLinear}
\qed

\pause
\medskip
We will see how the matrix
representations of the two functions combine to make
the matrix representation of their composition.
\end{frame}




%..........
\begin{frame}
\ex
Consider two linear functions $\map{h}{V}{W}$ and $\map{g}{W}{X}$
represented as here.
\begin{equation*}
  H=
  \rep{h}{B,C}=
  \begin{mat}
    3 &1 \\
    2 &5 \\
    4 &6
  \end{mat}
  \qquad
  G=
  \rep{g}{C,D}=
  \begin{mat}
    8 &7 &11 \\
    9 &10 &12 
  \end{mat}
\end{equation*}
(The sizes of the matrices show that 
$V$ has dimension~$2$, 
$W$ has dimension~$3$, 
and $X$ has dimension~$2$.)

We want to see how these two matrices combine to represent the map
$\map{\composed{g}{h}}{V}{X}$.

\pause
We will compute the action of $\composed{g}{h}$ by first computing the action
of~$h$ on a vector~$\vec{v}\in V$.
\begin{equation*}
  \rep{h(\vec{v})}{C}
  =\rep{h}{B,C}\cdot\rep{\vec{v}}{B}
  =
  \begin{mat}
    3 &1 \\
    2 &5 \\
    4 &6
  \end{mat}
  \colvec{v_1 \\ v_2}  
  =
  \colvec{3v_1+v_2 \\ 2v_1+5v_2 \\ 4v_1+6v_2}
\end{equation*}
\end{frame}
\begin{frame}
Apply $g$ to that.
\begin{multline*}
  \rep{g}{C,D}\cdot \rep{h(\vec{v})}{C}
  =
  \begin{mat}
    8 &7 &11 \\
    9 &10 &12     
  \end{mat}
  \colvec{3v_1+v_2 \\ 2v_1+5v_2 \\ 4v_1+6v_2}                \\
  =
  \colvec{8(3v_1+v_2)+7(2v_1+5v_2)+11(4v_1+6v_2)  \\
          9(3v_1+v_2)+10(2v_1+5v_2)+12(4v_1+6v_2)}
\end{multline*}
Gather terms.
\begin{equation*}
  =\colvec{(8\cdot 3+7\cdot 2+11\cdot 4)v_1+(8\cdot 1+7\cdot 5+11\cdot 6)v_2 \\
           (9\cdot 3+10\cdot 2+12\cdot 4)v_1+(9\cdot 1+10\cdot 5+12\cdot 6)v_2}
\end{equation*}
Rewrite that as a matrix-vector multiplication.
\begin{equation*}
  \begin{mat}
    8\cdot 3+7\cdot 2+11\cdot 4 &8\cdot 1+7\cdot 5+11\cdot 6 \\
    9\cdot 3+10\cdot 2+12\cdot 4 &9\cdot 1+10\cdot 5+12\cdot 6
  \end{mat}
  \colvec{v_1 \\ v_2}
\end{equation*}
Here is the combination.
\begin{equation*}
  \begin{mat}
    8 &7 &11 \\
    9 &10 &12 
  \end{mat}
  \begin{mat}
    3 &1 \\
    2 &5 \\
    4 &6
  \end{mat}
  =
  \begin{mat}
    8\cdot 3+7\cdot 2+11\cdot 4 &8\cdot 1+7\cdot 5+11\cdot 6 \\
    9\cdot 3+10\cdot 2+12\cdot 4 &9\cdot 1+10\cdot 5+12\cdot 6
  \end{mat}
\end{equation*}
\end{frame}




%..........
\begin{frame}{Definition of matrix multiplication}
\df[def:MatMult]
\ExecuteMetaData[../map4.tex]{df:MatMult}
\ex
\begin{equation*}
  \begin{mat}
    3 &1 &6 \\
    2 &5 &9
  \end{mat}
  \begin{mat}
    2 &0  &4 \\
    1 &-3 &5 \\
    4 &2  &7
  \end{mat}
  =
  \begin{mat}
    31  &9  &59  \\
    45  &3  &96
  \end{mat}
\end{equation*}
\end{frame}
\begin{frame}
\ex
This product is not defined.
\begin{equation*}
  \begin{mat}
    1  &3  &-1 \\
    0  &0  &0  \\
    2  &0  &0
  \end{mat}
  \begin{mat}
    5  &7  &1 \\
    2  &2  &0 
  \end{mat}
\end{equation*}

\pause
\ex
Square matrices of the same size have a defined product.
\begin{equation*}
  \begin{mat}
    1  &3  &-1 \\
    0  &0  &0  \\
    2  &0  &0
  \end{mat}
  \begin{mat}
    5  &7  &1 \\
    2  &2  &0 \\
    1  &-1 &2 
  \end{mat}
  =
  \begin{mat}
    11  &14  &-5  \\
     0  &0   &0   \\
    10  &14  &2
  \end{mat}
\end{equation*}
This reflects the fact that we can compose two
functions from a space to itself $\map{f,g}{V}{V}$.
\end{frame}




%..........
\begin{frame}{Matrix multiplication represents composition}
\th[th:MatMultRepComp]
\ExecuteMetaData[../map4.tex]{th:MatMultRepComp}
\pause
\pf
\ExecuteMetaData[../map4.tex]{pf:MatMultRepComp0}
\end{frame}
\begin{frame}
\ExecuteMetaData[../map4.tex]{pf:MatMultRepComp1}
\qed
\end{frame}




%..........
\begin{frame}{Arrow diagrams}
% \ExecuteMetaData[../map4.tex]{MatMultArrowDiag0}
This pictures the relationship between maps and matrices.
\centergraphic{../ch3.20}
\pause
\ExecuteMetaData[../map4.tex]{MatMultArrowDiag1}
\end{frame}



\begin{frame}{Matrix multiplication is not commutative}
Composition of function is not a commutative operation\Dash $\cos(x^2)$
is different than $\cos^2(x)$.
This also holds in the special case of 
composition of linear functions.
\pause
\ex
Changing the order in which we multiply these matrices
\begin{equation*}
  \begin{mat}
    3  &3  \\
    0  &4
  \end{mat}
  \begin{mat}
    -2  &6  \\
    6   &5
  \end{mat}
  =
  \begin{mat}
    12  &33 \\
    24  &20
  \end{mat}
\end{equation*}
changes the result.
\begin{equation*}
  \begin{mat}
    -2  &6  \\
    6   &5
  \end{mat}
  \begin{mat}
    3  &3  \\
    0  &4
  \end{mat}
  =
  \begin{mat}
     -6  &18   \\
     18  &38  
  \end{mat}
\end{equation*}
\pause
\ex
The product of these matrices
\begin{equation*}
  \begin{mat}
    3  &4  \\
    0  &2
  \end{mat}
  \qquad
  \begin{mat}
    8  &12  &0 \\
   -4  &0  &1/2
  \end{mat}
\end{equation*}
is defined in one order and not defined in the other.
\end{frame}




%..........
\begin{frame}
\th[th:MatMultWellBehaved]
\ExecuteMetaData[../map4.tex]{th:MatMultWellBehaved}
\pause
\pf
\ExecuteMetaData[../map4.tex]{pf:MatMultWellBehaved0}

\pause
\ExecuteMetaData[../map4.tex]{pf:MatMultWellBehaved1}
\qed
\end{frame}



% ..... Three.IV.2 .....
\section{Mechanics of Matrix Multiplication}
%..........
\begin{frame}
\df[df:UnitMatrix]
\ExecuteMetaData[../map4.tex]{df:UnitMatrix}
\end{frame}




%..........
\begin{frame}
\lm[lm:ColsAndRowsInMatrixMult]
\ExecuteMetaData[../map4.tex]{lm:ColsAndRowsInMatrixMult}
\end{frame}
\begin{frame}
\pf
\ExecuteMetaData[../map4.tex]{pf:ColsAndRowsInMatrixMult}
\qed
\end{frame}




%..........
\begin{frame}
\df[df:MainDiagonal]
\ExecuteMetaData[../map4.tex]{df:MainDiagonal}
\pause
\df[df:IdentityMatrix]
\ExecuteMetaData[../map4.tex]{df:IdentityMatrix}
\end{frame}




%..........
\begin{frame}
\df[df:DiagonalMatrix]
\ExecuteMetaData[../map4.tex]{df:DiagonalMatrix}
\end{frame}




%..........
\begin{frame}
\df[df:PermutationMatrix]
\ExecuteMetaData[../map4.tex]{df:PermutationMatrix}
\end{frame}




%..........
\begin{frame}
\df[df:ElementaryReductionMatrices]
\ExecuteMetaData[../map4.tex]{df:ElementaryReductionMatrices}
\end{frame}




\begin{frame}
\lm[GrByMatMult]
\ExecuteMetaData[../map4.tex]{lm:GrByMatMult}
\pf
Clear.
\qed
\co[cor:ReducViaMatrices]
\ExecuteMetaData[../map4.tex]{co:ReducViaMatrices}
\end{frame}



% ..... Three.IV.3 .....
\section{Inverses}
%..........
\begin{frame}{Definition of matrix inverse}
\df[df:MatrixInverse]
\ExecuteMetaData[../map4.tex]{df:MatrixInverse}
\end{frame}




%..........
\begin{frame}
\lm[le:LeftAndRightInvEqual]
\ExecuteMetaData[../map4.tex]{lm:LeftAndRightInvEqual}
\pause
\th[th:MatrixInvertibleIffNonsingular]
\ExecuteMetaData[../map4.tex]{th:MatrixInvertibleIffNonsingular}
\pause
\pf
\ExecuteMetaData[../map4.tex]{pf:MatrixInvertibleIffNonsingular}
\qed
\end{frame}




%..........
\begin{frame}
\lm[lem:ProdInvIsInv]
\ExecuteMetaData[../map4.tex]{lm:ProdInvIsInv}
\pause
\pf
\ExecuteMetaData[../map4.tex]{pf:ProdInvIsInv0}

\pause
\ExecuteMetaData[../map4.tex]{pf:ProdInvIsInv1}
\qed

\pause
Here is the arrow diagram for matrix inverses.
\centergraphic{../ch3.21}
\end{frame}




\begin{frame}
\lm[lem:ComputeInvMat]
\ExecuteMetaData[../map4.tex]{lm:ComputeInvMat}
\pause
\pf
\ExecuteMetaData[../map4.tex]{pf:ComputeInvMat0}

\pause
\ExecuteMetaData[../map4.tex]{pf:ComputeInvMat1}

\pause
\ExecuteMetaData[../map4.tex]{pf:ComputeInvMat2}
\qed  
\end{frame}




\begin{frame}
\co[cor:TwoByTwoInv]
\ExecuteMetaData[../map4.tex]{co:TwoByTwoInv}
\pause
\pf
\ExecuteMetaData[../map4.tex]{pf:TwoByTwoInv}
\qed  
\end{frame}


%...........................
% \begin{frame}
% \ExecuteMetaData[../gr3.tex]{GaussJordanReduction}
% \df[def:RedEchForm]
% 
% \end{frame}
\end{document}
