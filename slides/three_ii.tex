% see: https://groups.google.com/forum/?fromgroups#!topic/comp.text.tex/s6z9Ult_zds
\makeatletter\let\ifGm@compatii\relax\makeatother 
\documentclass[10pt,t]{beamer}
\usefonttheme{professionalfonts}
\usefonttheme{serif}
\PassOptionsToPackage{pdfpagemode=FullScreen}{hyperref}
\PassOptionsToPackage{usenames,dvipsnames}{color}
% \DeclareGraphicsRule{*}{mps}{*}{}
\usepackage{../linalgjh}
\usepackage{present}
\usepackage{xr}\externaldocument{../map2} % read refs from .aux file
\usepackage{xr}\externaldocument{../vs3} % read refs from .aux file
\usepackage{catchfilebetweentags}
\usepackage{etoolbox} % from http://tex.stackexchange.com/questions/40699/input-only-part-of-a-file-using-catchfilebetweentags-package
\makeatletter
\patchcmd{\CatchFBT@Fin@l}{\endlinechar\m@ne}{}
  {}{\typeout{Unsuccessful patch!}}
\makeatother

\mode<presentation>
{
  \usetheme{boxes}
  \setbeamercovered{invisible}
  \setbeamertemplate{navigation symbols}{} 
}
\addheadbox{filler}{\ }  % create extra space at top of slide 
\hypersetup{colorlinks=true,linkcolor=blue} 

\title[Homomorphisms] % (optional, use only with long paper titles)
{Three.II Homomorphisms}

\author{\textit{Linear Algebra} \\ {\small Jim Hef{}feron}}
\institute{
  \texttt{http://joshua.smcvt.edu/linearalgebra}
}
\date{}


\subject{Homomorphisms}
% This is only inserted into the PDF information catalog. Can be left
% out. 

\begin{document}
\begin{frame}
  \titlepage
\end{frame}

% =============================================
% \begin{frame}{Reduced Echelon Form} 
% \end{frame}



% ..... Three.II.1 .....
\section{Definition}
%..........
\begin{frame}{Homomorphism}
\df[def:Homo]
\ExecuteMetaData[../map2.tex]{df:Homo}
\end{frame}




%..........
\begin{frame}
\ex
The function $\map{h}{\polyspace_2}{\Re^2}$ given by
\begin{equation*}
  h(a+bx+cx^2)
  =
  \colvec{a+c \\ 0}
\end{equation*}
is a homomorphism. 
(Note that it is neither one-to-one nor onto.)
\pause
Showing that it respects addition is routine.
\begin{gather*}
  h(\,(a_1+b_1x+c_1x^2)+(a_2+b_2x+c_2x^2)\,)      \\
  \begin{align*}
    \qquad
    &=h(\,(a_1+a_2)+(b_1+b_2)x+(c_1+c_2)x^2\,)     \\
    &=\colvec{a_1+a_2+c_1+c_2 \\ 0}                 \\
    &=\colvec{a_1+c_1 \\ 0}+\colvec{a_2+c_2 \\ 0}   \\
    &=h(a_1+b_1x+c_1x^2)+h(a_2+b_2x+c_2x^2)       
  \end{align*}
\end{gather*}
\pause
So is showing that it respects scalar multiplication.
\begin{equation*}
  r\cdot h(a+bx+cx^2)
  =r\cdot\colvec{a+c \\ 0}  
  =\colvec{ra+rc \\ 0}
  =h(\,r(a+bx+cx^2)\,)
\end{equation*}
\end{frame}



%..........
\begin{frame}
\ex
Of these two maps $\map{h,g}{\Re^2}{\Re}$,
the first is a homomorphism while the second is not.
\begin{equation*}
  \colvec{x \\ y}\mapsunder{h} 2x-3y
  \qquad
  \colvec{x \\ y}\mapsunder{g} 2x-3y+1
\end{equation*}

\pause
The map $h$ respects addition
\begin{multline*}
  h(\colvec{x_1 \\ y_1}+\colvec{x_2 \\ y_2})
  =h(\colvec{x_1+x_2 \\ y_1+y_2})             
  =2(x_1+x_2)-3(y_1+y_2)                    \\
  =(2x_1-3y_1)+(2x_2-3y_2)
  =h(\colvec{x_1 \\ y_1})+h(\colvec{x_2 \\ y_2})
\end{multline*}
and scalar multiplication.
\begin{equation*}
  r\cdot h(\colvec{x \\ y})
  =r\cdot(2x-3y)
  =2rx-3ry
  =(2r)x-(3r)y
  =h(r\cdot\colvec{x \\ y})
\end{equation*}

\pause
In contrast, $g$ does not respect addition.
\begin{equation*} 
  g(\colvec{1 \\ 4}+\colvec{5 \\ 6})=-17
  \qquad
  g(\colvec{1 \\ 4})+g(\colvec{5 \\ 6})=-16
\end{equation*}
\end{frame}




%..........
\begin{frame}
We proved these two while studying isomorphisms.

\lm[le:HomoSendsZeroToZero]\hspace*{-1em}
\ExecuteMetaData[../map2.tex]{lm:HomoSendsZeroToZero}

\lm[le:HomoPreserveLinCombo]\hspace*{-1em}
\ExecuteMetaData[../map2.tex]{lm:HomoPreserveLinCombo}

\medskip
To verify that a map is a homomorphism the one that we use most often
is statement~(2). 

\pause
\ex
Between any two vector spaces the zero map $\map{Z}{V}{W}$ given by
$Z(\vec{v})=\zero_W$ is a linear map.
Using~(2): 
$Z(c_1\vec{v}_1+c_2\vec{v}_2)=\zero_W
   =\zero_W+\zero_W=c_1Z(\vec{v}_1)+c_2Z(\vec{v}_2)$.
\end{frame}




%..........
\begin{frame}
\ex
The \definend{inclusion map} $\map{\iota}{\Re^2}{\Re^3}$
\begin{equation*}
  \iota(\colvec{x  \\ y})
  =\colvec{x \\ y \\ 0}
\end{equation*}
is a homomorphism.
\begin{align*}
  \iota(c_1\cdot\colvec{x_1 \\ y_1}+c_2\cdot\colvec{x_2 \\ y_2})
  &=\iota(\colvec{c_1x_1+c_2x_2 \\ c_1y_1+c_2y_2})       \\
  &=\colvec{c_1x_1+c_2x_2 \\ c_1y_1+c_2y_2 \\ 0}      \\
  &=\colvec{c_1x_1 \\ c_1y_1 \\ 0}
   +\colvec{c_2x_2 \\ c_2y_2 \\ 0}                    \\
  &=c_1\cdot\iota(\colvec{x_1 \\ y_1})+c_2\cdot\iota(\colvec{x_2 \\ y_2})
\end{align*}
\end{frame}




%..........
\begin{frame}
\ex
Consider 
this function $\map{h}{\polyspace_1}{\polyspace_1}$.
\begin{equation*}
  h(a+bx)=b+bx
\end{equation*}
Here are two examples of the action of this function: $1+2x\mapsto 2+2x$
and $3-x\mapsto-1-x$. 

\pause
This is a linear map.
\begin{multline*}
  h(\,c_1\cdot (a_1+b_1x)+c_2\cdot(a_2+b_2x)\,)                  \\
  \begin{aligned}
    &=h(\,(c_1a_1+c_2a_2)+(c_1b_1+c_2b_2)x\,)       \\
    &=(c_1b_1+c_2b_2)+(c_1b_1+c_2b_2)x          \\
    &=(c_1b_1+c_1b_1x)+(c_2b_2+c_2b_2x)         \\
    &=c_1\cdot h(a_1+b_1x)+c_2\cdot h(a_2+b_2x)
  \end{aligned}
\end{multline*}
\end{frame}




%..........
\begin{frame}
\ex
The derivative
is the usual transformation of polynomial space
$\map{d/dx}{\polyspace_2}{\polyspace_1}$.
\begin{equation*}
  d/dx\,(ax^2+bx+c)=2ax+b
\end{equation*}
For instance, $d/dx\,(3x^2-2x+4)=6x-2$
and $d/dx\,(x^2+1)=2x$.

\pause
This map is a homomorphism.
\begin{multline*}
  d/dx\,\big(\,r_1(a_1x^2+b_1x+c_1)+r_2(a_2x^2+b_2x+c_2)\,\big)  \hspace*{5em}  \\
  \begin{aligned} 
    &=d/dx\,\big(\,(r_1a_1+r_2a_2)x^2+(r_1b_1+r_2b_2)x+(r_1c_1+r_2c_2)\,\big)   \\
    &=2(r_1a_1+r_2a_2)x+(r_1b_1+r_2b_2)   \\
    &=(2r_1a_1x+r_1b_1)+(2r_2a_2x+r_2b_2)   \\
    &=r_1\cdot d/dx\,(a_1x^2+b_1x+c_1)
      +r_2\cdot d/dx\,(a_2x^2+b_2x+c_2)
  \end{aligned}
\end{multline*}
\end{frame}



%..........
\begin{frame}
\ex
The \definend{trace} of a square matrix 
is the sum down the upper-left to lower-right diagonal.
Thus
$\map{\trace}{\matspace_{\nbyn{2}}}{\Re}$
is this.
\begin{equation*}
  \trace(\begin{mat}
    a &b \\
    c &d
  \end{mat})
  =a+d
\end{equation*}
It is linear.
\begin{multline*}
  \trace(\,
  r_1\cdot\begin{mat}
    a_1 &b_1 \\
    c_1 &d_1
  \end{mat}
  +
  r_2\cdot\begin{mat}
    a_2 &b_2 \\
    c_2 &d_2
  \end{mat}
  \,)                                              \\
  \begin{aligned}
    &=\trace(
      \begin{mat}
        r_1a_1+r_2a_2 &r_1b_1+r_2b_2 \\
        r_1c_1+r_2c_2 &r_1d_1+r_2d_2
      \end{mat}
      )                                       \\
    &=(r_1a_1+r_2a_2)+(r_1d_1+r_2d_2)         \\
    &=r_1(a_1+d_1)+r_2(a_2+d_2)               \\
    &=r_1\cdot\trace(
      \begin{mat}
        a_1 &b_1 \\
        c_1 &d_1
      \end{mat}
      )
      +
      r_2\cdot\trace(
      \begin{mat}
        a_2 &b_2 \\
        c_2 &d_2
      \end{mat}
      )
  \end{aligned} 
\end{multline*}
\end{frame}



%..........
\begin{frame}
\th[th:HomoDetActOnBasis]
\ExecuteMetaData[../map2.tex]{th:HomoDetActOnBasis}

\pause
\pf
\ExecuteMetaData[../map2.tex]{pf:HomoDetActOnBasis0}

\pause
\ExecuteMetaData[../map2.tex]{pf:HomoDetActOnBasis1}
\end{frame}
\begin{frame}
\ExecuteMetaData[../map2.tex]{pf:HomoDetActOnBasis2}
\qed

\pause % \medskip
\df[df:ExtendedLinearly]
\ExecuteMetaData[../map2.tex]{df:ExtendedLinearly}
\end{frame}




%..........
\begin{frame}
\ex 
One basis of the space of quadratic polynomials $\polyspace_2$
is $B=\sequence{x^2,x,1}$.
We can define a map $\map{\text{eval}_3}{\polyspace_2}{\Re}$ 
by specifying its action on that basis
\begin{equation*}
  x^2\mapsunder{\text{eval}_3}9
  \quad
  x\mapsunder{\text{eval}_3}3
  \quad
  1\mapsunder{\text{eval}_3}1
\end{equation*}
and then extending linearly.
\begin{align*}
  \text{eval}_3(ax^2+bx+c)
   &=a\cdot\text{eval}_3(x^2)
     +b\cdot\text{eval}_3(x)
     +c\cdot\text{eval}_3(1)     \\
   &=9a+3b+c
\end{align*}
For instance,
$\text{eval}_3(x^2+2x+3)=9+6+3=18$.

\pause
On the basis elements, we can describe the action of this map as: 
plugging the value~$3$ in for $x$. 
That remains true when we extend linearly, so
$\text{eval}_3(\,p(x)\,)=p(3)$.
\end{frame}




%..........
\begin{frame}
\ex
Consider the standard basis $\stdbasis_2$ for the vector space $\Re^2$.
We can specify a rotation of the two basis vectors as here.
\begin{equation*}
  \colvec{1 \\ 0}\mapsto\colvec[r]{\cos\theta \\ \sin\theta}
  \qquad
  \colvec{0 \\ 1}\mapsto\colvec[r]{-\sin\theta \\ \cos\theta}
  \qquad
  \vcenteredhbox{\includegraphics{asy/three_ii_rotate.pdf}}
\end{equation*}
\pause
Extend linearly
to get a homomorphism $\map{t_{\theta}}{\Re^2}{\Re^2}$. 
\begin{align*}
  t_{\theta}(\colvec{x \\ y})
  &=
  t_{\theta}(x\cdot\colvec{1 \\ 0}+y\cdot\colvec{0 \\ 1})  \\
  &=
  x\cdot t_{\theta}(\colvec{1 \\ 0})+y\cdot t_{\theta}(\colvec{0 \\ 1})  \\
  &=x\cdot\colvec[r]{\cos\theta \\ \sin\theta}
    +y\cdot\colvec[r]{-\sin\theta \\ \cos\theta}  \\
  &=\colvec{x\cos\theta-y\sin\theta \\ x\sin\theta+y\cos\theta}
\end{align*}
% \pause
% (This map is one-to-one and onto, so it is an automorphism.)
\end{frame}




%..........
\begin{frame}
\df[df:LinearTransformation]
\ExecuteMetaData[../map2.tex]{df:LinearTransformation}

\pause
\ex
For any vector space $V$ the \definend{identity} map $\map{\textrm{id}}{V}{V}$
given by $\vec{v}\mapsto\vec{v}$ is a linear transformation.
The check is easy.

\pause
\ex
In $\Re^3$ the function $f_{yz}$  
that reflects vectors over the $yz$-plane 
\begin{equation*}
  \colvec{x \\ y \\ z}\mapsunder{f_{yz}}\colvec{-x \\ y \\ z}
\end{equation*}
is a linear
transformation.
\begin{multline*}
  f_{yz}(r_1\colvec{x_1 \\ y_1 \\ z_1}+r_2\colvec{x_2 \\ y_2 \\ z_2})
  =f_{yz}(\colvec{r_1x_1+r_2x_2 \\ r_1y_1+r_2y_2 \\ r_1z_1+r_2z_2})  
  =\colvec{-(r_1x_1+r_2x_2) \\ r_1y_1+r_2y_2 \\ r_1z_1+r_2z_2}    \\
  =r_1\colvec{-x_1 \\ y_1 \\ z_1}+r_2\colvec{-x_2 \\ y_2 \\ z_2}  
  =r_1f_{yz}(\colvec{x_1 \\ y_1 \\ z_1})+r_2f_{yz}(\colvec{x_2 \\ y_2 \\ z_2}) 
\end{multline*}
\end{frame}



%..........
\begin{frame}
\lm[le:SpLinFcns]\hspace*{-1em}
\ExecuteMetaData[../map2.tex]{lm:SpLinFcns}

\ExecuteMetaData[../map2.tex]{SpLinFcns}

\iftoggle{showallproofs}{
  \pause
  \pf\hspace*{-1em}
  \ExecuteMetaData[../map2.tex]{pf:SpLinFcns}
  \qed
}{
  \bigskip
  The book contains the lemma's proof.
}
\end{frame}
\begin{frame}
\ex
Consider $\linmaps{\Re}{\Re^2}$.
Fix these bases for the two spaces.
\begin{equation*}
  B_{\Re}=\stdbasis_1=\sequence{1}
  \qquad
  B_{\Re^2}=\stdbasis_2=\sequence{\colvec{1 \\ 0}, 
                                \colvec{0 \\ 1}}
\end{equation*}
A linear map is determined by its action on a basis of the domain space.
Thus the functions that are elements of $\linmaps{\Re}{\Re^2}$
\begin{equation*}
  1\mapsunder{t} c_1\colvec{1 \\ 0}+c_2\colvec{0 \\ 1}
\end{equation*}
are determined by $c_1$ and $c_2$.
We could write each such map as $t=t_{c_1,c_2}$.
So $\linmaps{\Re}{\Re^2}$ is a dimension~$2$ space.
\pause
\ex
Similarly, for $\linmaps{\Re^2}{\Re^3}$, fix
$\stdbasis_2=\sequence{\vec{e}_1, \vec{e}_2}$ and 
$\stdbasis_3=\sequence{\vec{e}_1, \vec{e}_2, \vec{e}_3}$
(note that the $\vec{e}_1$'s are different; 
for instance, one is two-tall while the other is three-tall).
We can characterize the elements 
of $\linmaps{\Re^2}{\Re^3}$ in this way.
\begin{equation*}
  \vec{e}_1\mapsunder{t} c_1\vec{e}_1+c_2\vec{e}_2+c_3\vec{e}_3
  \qquad
  \vec{e}_2\mapsunder{t} d_1\vec{e}_1+d_2\vec{e}_2+d_3\vec{e}_3
\end{equation*}
So, $\linmaps{\Re^2}{\Re^3}$ is six-dimensional.
\end{frame}





% ..... Three.II.2 .....
\section{Range space and null space}
%..........
\begin{frame}
\lm[le:RangeIsSubSp]
\ExecuteMetaData[../map2.tex]{lm:RangeIsSubSp}

\pause
\pf
\ExecuteMetaData[../map2.tex]{pf:RangeIsSubSp}
\qed

\pause
\ex
For any angle $\theta$, 
the function $\map{t_{\theta}}{\Re^2}{\Re^2}$ that rotates 
vectors counterclockwise by $\theta$ is a homomorphism.
In the domain~$\Re^2$ each line through the origin is a subspace.
The image of that line under this map is another line through the origin, 
a subspace of the codomain~$\Re^2$. 
\end{frame}




%..........
\begin{frame}{Range space}
\df[df:RangeSpace]
\ExecuteMetaData[../map2.tex]{df:RangeSpace}

\pause
\ex
Projection $\map{\pi}{\Re^3}{\Re^2}$
\begin{equation*}
  \colvec{x \\ y \\ z}\mapsto\colvec{x \\ y}
\end{equation*}
is a linear map; the check is routine.
The range space is $\rangespace{\pi}=\Re^2$
because given a vector $\vec{w}\in\Re^2$ 
\begin{equation*}
  \vec{w}=\colvec{a \\ b}
\end{equation*}
we can find a
$\vec{v}\in\Re^3$ that maps to it, specifically any $\vec{v}$ with a 
first component~$a$ and second component~$b$.
Thus the rank of $\pi$ is~$2$.
\end{frame}
\begin{frame}
\ex
The derivative map
$\map{d/dx}{\Re^4}{\Re^4}$
is linear.
Its range is $\rangespace{d/dx}=\set{a_0+a_1x+a_2x^2+a_3x^3\suchthat a_i\in\Re}$.
(Verifying that every member of that space is the derivative of some fourth
degree polynomial is easy.)
The rank of the derivative function is~$3$. 

\pause
\ex
This map from $\matspace_{\nbyn{2}}$ to $\Re^2$ is linear; the check is routine.
\begin{equation*}
  \begin{mat}
    a &b \\
    c &d
  \end{mat}
  \mapsunder{h}
  \colvec{a+b  \\ 2a+2b}
\end{equation*}
The range space is this line through the origin
\begin{equation*}
  \set{\colvec{t \\ 2t} \suchthat t\in\Re}
\end{equation*}
(every member of that set is the image 
\begin{equation*}
  \colvec{t \\ 2t}
  =
  h(
    \begin{mat}
      t  &0 \\
      0   &0
    \end{mat}
   )
\end{equation*}
of a $\nbyn{2}$ matrix).
The rank of this map is $1$.
\end{frame}




%..........
\begin{frame}{Homomorphisms organize the domain}
In moving from isomorphisms to homomorphisms we dropped 
the requirement that the maps be onto and one-to-one.
Dropping the onto condition has no effect in the sense
that any homomorphism $\map{h}{V}{W}$ is onto some space,
namely its range space $\rangespace{h}$.

\pause
Consider the effect of dropping the one-to-one condition.
With that restriction gone, for some vectors $\vec{w}\in W$
in the range there may be many vectors $\vec{v}\in V$ mapped to $\vec{w}$.
(To avoid a confused picture, below there is only one `$\mapsto$' arrow for 
many domain elements.) 
\centergraphic{../ch3.5}
\ExecuteMetaData[../map2.tex]{InverseImage}
\end{frame}
\begin{frame}
\ex
The projection map $\map{\pi}{\Re^2}{\Re}$ is linear.
\begin{equation*}
  \pi(\colvec{x \\ y})
  =x
\end{equation*}
\pause
We can identify the codomain $\Re$ with the $x$-axis in $\Re^2$.
Here is a member of the $x$-axis, outlined in red.
\centergraphic{asy/three_ii_proj1.pdf}
\pause
Next are some elements of $\pi^{-1}(2)$, 
shown both as dots (as in the bean diagram) and as vectors.
The vectors are also red because they are associated by $\pi$ with $2$.
\centergraphic{asy/three_ii_proj2.pdf}
Think of these as ``$2$~vectors.''
\end{frame}\begin{frame}
Here are some ``$3$-vectors,'' inverse images of $3$.
\centergraphic{asy/three_ii_proj3.pdf}
\pause
The definition of addition preservation is that
$\pi(\vec{u}+\vec{v})=\pi(\vec{u})+\pi(\vec{v})$.
Therefore
where $\pi(\vec{u})=2$ and $\pi(\vec{v})=3$,
the vector sum $\vec{u}+\vec{v}$ will be mapped by $\pi$ to $5$.
\centergraphic{asy/three_ii_proj5.pdf}
Thus, we can understand the definition of addition preservation as:
red plus blue makes purple\Dash a ``$2$ vector'' plus a
``$3$~vector'' sums to a ``$5$~vector.''
\pause
Preservation of scalar multiplication has a similar interpretation.
\end{frame}




%..........
\begin{frame}
The same analysis holds for any homomorphism.

\ex
The projection $\map{\pi}{\Re^3}{\Re^2}$ is a linear map.
As above we can identify the codomain with the $xy$-plane inside of
$\Re^3$.
\only<1>{\centergraphic{asy/three_ii_3dproj1.pdf}}
\only<2>{\centergraphic{asy/three_ii_3dproj2.pdf}}
\only<3->{\centergraphic{asy/three_ii_3dproj3.pdf}}
In the $xy$-plane, red plus blue makes purple as shown by the parallelogram.
We will illustrate that a $\vec{w}_1$ vector plus a
  $\vec{w}_2$ vector is a $\vec{w}_3$ vector

\pause
Consider the inverse image sets; the diagram shows some of the infinitely 
many points in each $\pi^{-1}(\vec{w}_i)$.
\pause
If we take a $\vec{v}_1\in\pi^{-1}(\vec{w}_1)$ 
and a $\vec{v}_2\in\pi^{-1}(\vec{w}_2)$
then they sum to a
$\vec{v}_3\in\pi^{-1}(\vec{w}_3)$.
\end{frame}




%..........
\begin{frame}
This also holds when the spaces are not ones that we can conveniently draw.

\ex
Consider $\map{h}{\polyspace_2}{\Re^2}$
\begin{equation*}
  ax^2+bx+c\mapsto\colvec{b \\ b}
\end{equation*}
and consider these three members of the range.
\begin{equation*}
  \vec{w}_1=\colvec{1 \\ 1},\;
  \vec{w}_2=\colvec{-1 \\ -1},\;   
  \vec{w}_3=\colvec{0 \\ 0}
\end{equation*}
\pause
The inverse image of $\vec{w}_1$ is 
$h^{-1}(\vec{w}_1)=\set{a_1x^2+x+c_1\suchthat a_1,c_1\in\Re^2}$.
Think of these as ``$\vec{w}_1$~vectors.''
Some examples are $3x^2+x+1$, $3x^2+x-4$, and $-2x^2+x$.
\pause
The inverse image of $\vec{w}_2$ is 
$h^{-1}(\vec{w}_2)=\set{a_2x^2-x+c_2\suchthat a_2,c_2\in\Re^2}$;
these are ``$\vec{w}_2$~vectors.''
The ``$\vec{w}_3$~vectors'' are members of the set
$h^{-1}(\vec{w}_3)=\set{a_3x^2+c_3\suchthat a_3,c_3\in\Re^2}$.

\pause
As above, any $\vec{v}_1\in h^{-1}(\vec{w}_1)$
plus any $\vec{v}_2\in h^{-1}(\vec{w}_2)$
equals a $\vec{v}_3\in h^{-1}(\vec{w}_3)$:
a quadratic with an $x$~coefficient of $1$ 
plus a quadratic with an $x$~coefficient of $-1$
equals a quadratic with an $x$~coefficient of~$0$.
That is, a ``$\vec{w}_1$~vector'' plus a
``$\vec{w}_2$~vector'' is a ``$\vec{w}_3$~vector.'' 
\end{frame}



\begin{frame}
In each of those examples, because there is a homomorphism
$\map{h}{V}{W}$ we can view the domain $V$ as organized into the 
inverse images $h^{-1}(\vec{w})$ for each $\vec{w}\in\rangespace{h}$.

We say ``organized'' because these inverse image sets 
reflect the structure of the range
in that a ``$\vec{w}_1$~vector'' plus a ``$\vec{w}_2$~vector'' 
equals a ``$\vec{w}_1+\vec{w}_2$~vector.''
\end{frame}




%..........
\begin{frame}{Null space}
Vector spaces have a distinguished element, $\vec{0}$.
So we next consider the inverse image of that element $h^{-1}(\zero)$.
\lm[le:NullspIsSubSp]\hspace*{-1em}
\ExecuteMetaData[../map2.tex]{lm:NullspIsSubSp}

\pause
\pf
\ExecuteMetaData[../map2.tex]{pf:NullspIsSubSp}
\qed

\pause
\medskip
\no
This result complements \nearbylemma{le:RangeIsSubSp}
that for any subspace of the domain its image is a subspace of the range.
\end{frame}




%..........
\begin{frame}
\df[df:NullSpace]
\ExecuteMetaData[../map2.tex]{df:NullSpace}

\centergraphic{../ch3.10}
\pause
\no 
Strictly, the trivial subspace of the codomain is not $\zero_{W}$, it is 
$\set{\zero_{W}}$, and
so we may think to write the nullspace as $h^{-1}(\set{\zero_{W}})$.
But we have defined the two sets $h^{-1}(\vec{w})$
and $h^{-1}(\set{\vec{w}})$ to be equal
and the first is easier to write.
\end{frame}




%..........
\begin{frame}
\ex
The derivative function $\map{d/dx}{\polyspace_2}{\polyspace_1}$
is linear.
\begin{equation*}
  \nullspace{d/dx}=\set{ax^2+bx+c \suchthat
                                  2ax+b=0}
\end{equation*}
The polynomial $2ax+b$ equals the zero polynomial if and
only if they have the same constant coefficient (which implies that 
$b=0$), 
the same coefficient of~$x$ (which implies that $a=0$), and the same
coefficient of~$x^2$ (which gives no restriction).
Thus the nullspace is this, and the nullity is $1$. 
\begin{equation*}
  \nullspace{d/dx}=\set{ax^2+bx+c \suchthat
                                  a=0,\, b=0,\, c\in\Re}
                  =\set{c\suchthat c\in\Re}
\end{equation*}

\pause
\ex
The function $\map{h}{\Re^2}{\Re^1}$ given by
\begin{equation*}
  \colvec{a \\ b}\mapsto 2a+b
\end{equation*}
has this null space.
\begin{equation*}
  \nullspace{h}
  =\set{\colvec{a \\ b}\suchthat 2a+b=0}
  =\set{\colvec{-b/2 \\ b}\suchthat b\in\Re}
\end{equation*}
Its nullity is $1$.
\end{frame}
\begin{frame}
\ex
The homomorphism $\map{f}{\matspace_{\nbyn{2}}}{\Re^2}$
\begin{equation*}
  \begin{mat}
    a &b \\
    c &d 
  \end{mat}
  \mapsunder{f}
  \colvec{a+b \\ c+d}
\end{equation*}
has this null space
\begin{align*}
  \nullspace{f}
  &=\set{
    \begin{mat}
      a  &b  \\
      c  &d  
    \end{mat}
    \suchthat 
    \text{$a+b=0$ and $c+d=0$}
    }                                 \\
  &=\set{
    \begin{mat}
      -b  &b  \\
      -d  &d
    \end{mat}
    \suchthat
    b,d\in\Re
    }
\end{align*}
and a nullity of $2$.

\pause
\ex
The dilation function $\map{d_{3}}{\Re^2}{\Re^2}$
\begin{equation*}
  \colvec{a  \\ b}\mapsto\colvec{3a \\ 3b}
\end{equation*}
has a trivial null space
$\nullspace{d_{3}}=\set{\zero}$
and its nullity is $0$.
\end{frame}





%..........
\begin{frame}{Rank plus nullity}
\th[th:RankPlusNullEqDim]
\ExecuteMetaData[../map2.tex]{th:RankPlusNullEqDim}

\pause
\pf
\ExecuteMetaData[../map2.tex]{pf:RankPlusNullEqDim0}

\pause
\ExecuteMetaData[../map2.tex]{pf:RankPlusNullEqDim1}
\end{frame}
\begin{frame}
\ExecuteMetaData[../map2.tex]{pf:RankPlusNullEqDim2}
\qed
\end{frame}
\begin{frame}
\ex
Projection $\map{\pi}{\Re^3}{\Re^2}$ 
\begin{equation*}
  \colvec{a \\ b \\ c}\mapsto\colvec{a \\ b}
\end{equation*}
takes a three-dimensional domain
to a two-dimensional range.  
Its null space is the $z$-axis so
its nullity is one.

\pause
This example illustrates the proof's steps particularly clearly.
Take 
the basis $B_N=\sequence{\vec{e}_3}$ for the null space. 
\pause
Expand that to the basis $\stdbasis_{3}$ for the entire domain.
\pause
The action of $\pi$ is that the third dimension collapses:
a linear combinations in the domain 
$\vec{v}=c_1\vec{e}_1+c_2\vec{e}_2+c_3\vec{e}_3$
is sent to the combination
$\vec{w}=c_1\vec{e}_1+c_2\vec{e}_2+\zero$
in the range.
Geometrically, the domain is organized into inverse images 
that are vertical lines, just like the null space.
% The action of $\pi$ is to zero them out. 
\centergraphic{asy/three_ii_dims.pdf}
\end{frame}

\begin{frame}
\ex
The derivative function $\map{d/dx}{\polyspace_2}{\polyspace_1}$
has this range space
\begin{equation*}
  \rangespace{d/dx}=\set{2ax+b\suchthat a, b\in\Re}=\polyspace_{1}
\end{equation*}
(any $cx+d\in\polyspace_{1}$ is the image of $ax^2+bx+c$ where
$a=c/2$, $b=d$, and $c$  can be any real)
and this null space.
\begin{equation*}
  \nullspace{d/dx}=\set{c \suchthat c\in\Re}
\end{equation*}
The rank is $2$ while the nullity is~$1$, and they add to the dimension
of the domain~$\polyspace_2$.
\pause
\ex
The function $\map{h}{\Re^2}{\Re^1}$ given by
\begin{equation*}
  \colvec{a \\ b}\mapsto 2a+b
\end{equation*}
has this range space
\begin{equation*}
  \rangespace{h}
  =\set{2a+b\suchthat a,b\in\Re}
  =\set{c\suchthat c\in\Re}
\end{equation*}
and this null space (calculated earlier).
\begin{equation*}
  \nullspace{h}
  =\set{\colvec{-b/2 \\ b}\suchthat b\in\Re}
\end{equation*}
Its rank is $1$ and its nullity is $1$.
Its domain $\Re^2$ has dimension~$2$.
\end{frame}
\begin{frame}
\ex
The dilation function $\map{d_{3}}{\Re^2}{\Re^2}$
\begin{equation*}
  \colvec{a  \\ b}\mapsto\colvec{3a \\ 3b}
\end{equation*}
has range space $\Re^2$
and a trivial nullspace
$\nullspace{d_{3}}=\set{\zero}$.
So its rank is~$2$
and its nullity is~$0$.
\pause
\ex
The homomorphism $\map{f}{\matspace_{\nbyn{2}}}{\Re^2}$
\begin{equation*}
  \begin{mat}
    a &b \\
    c &d 
  \end{mat}
  \mapsunder{f}
  \colvec{a+b \\ c+d}
\end{equation*}
has range space equal to $\Re^2$ (to get a vector with a first component of 
$x$ and a second component of $y$ we can take $a=x$, $b=0$, $c=y$, and $d=0$).
Thus $f$'s rank is~$2$.
We found its null space earlier
\begin{equation*}
  \nullspace{f}
  =\set{
    \begin{mat}
      -b  &b  \\
      -d  &d
    \end{mat}
    \suchthat
    b,d\in\Re
    }
\end{equation*}
and its nullity is $2$.
\end{frame}




%..........
\begin{frame}
\lm[lm:ImageLinearlyDependentIsLinearlyDependent]
\ExecuteMetaData[../map2.tex]{lm:ImageLinearlyDependentIsLinearlyDependent}

\pause
\pf
\ExecuteMetaData[../map2.tex]{pf:ImageLinearlyDependentIsLinearlyDependent}
\qed

\pause
\ex
The trace function $\map{\trace}{\matspace_{\nbyn{2}}}{\Re}$
\begin{equation*}
  \begin{mat}
    a  &b  \\
    c  &d
  \end{mat}
  \mapsto a+d
\end{equation*}
is linear.
This set of matrices is dependent.
\begin{equation*}
  S=\set{
    \begin{mat}
      1  &0  \\
      0  &0
    \end{mat},\,
    \begin{mat}
      0  &1  \\
      0  &0
    \end{mat},\,
    \begin{mat}
      2  &1  \\
      0  &0
    \end{mat}
    }
\end{equation*}
The three matrices map to $1$, $0$, and $2$ respectively.
The set $\set{1,0,2}$ is linearly dependent in $\Re$.
\end{frame}




%..........
\begin{frame}
\th[th:OOHomoEquivalence]
\ExecuteMetaData[../map2.tex]{th:OOHomoEquivalence}

\iftoggle{showallproofs}{
  \pause
  \pf
  \ExecuteMetaData[../map2.tex]{pf:OOHomoEquivalence0}
}{
  \bigskip
  The book has the proof.
}
\end{frame}
\iftoggle{showallproofs}{
  \begin{frame}
  \ExecuteMetaData[../map2.tex]{pf:OOHomoEquivalence1}

  \pause
  \ExecuteMetaData[../map2.tex]{pf:OOHomoEquivalence2}
  \end{frame}
  \begin{frame}
  \ExecuteMetaData[../map2.tex]{pf:OOHomoEquivalence3}
  \qed
  \end{frame}
}{}



%...........................
% \begin{frame}
% \ExecuteMetaData[../gr3.tex]{GaussJordanReduction}
% \df[def:RedEchForm]
% 
% \end{frame}
\end{document}
