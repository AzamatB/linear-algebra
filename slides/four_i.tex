% see: https://groups.google.com/forum/?fromgroups#!topic/comp.text.tex/s6z9Ult_zds
\makeatletter\let\ifGm@compote\relax\makeatother 
\documentclass[10pt,t]{beamer}
\usefonttheme{professionalfonts}
\usefonttheme{serif}
\PassOptionsToPackage{pdfpagemode=FullScreen}{hyperref}
\PassOptionsToPackage{usenames,dvipsnames}{color}
% \DeclareGraphicsRule{*}{mps}{*}{}
\usepackage{../linalgjh}
\usepackage{present}
\usepackage{xr}\externaldocument{../det1} % read refs from .aux file
\usepackage{xr}\externaldocument{../map4} % read refs from .aux file
\usepackage{catchfilebetweentags}
\usepackage{etoolbox} % from http://tex.stackexchange.com/questions/40699/input-only-part-of-a-file-using-catchfilebetweentags-package
\makeatletter
\patchcmd{\CatchFBT@Fin@l}{\endlinechar\m@ne}{}
  {}{\typeout{Unsuccessful patch!}}
\makeatother

\mode<presentation>
{
  \usetheme{boxes}
  \setbeamercovered{invisible}
  \setbeamertemplate{navigation symbols}{} 
}
\addheadbox{filler}{\ }  % create extra space at top of slide 
\hypersetup{colorlinks=true,linkcolor=blue} 

\title[Determinants] % (optional, use only with long paper titles)
{Four.I Definition of Determinant}

\author{\textit{Linear Algebra} \\ {\small Jim Hef{}feron}}
\institute{
  \texttt{http://joshua.smcvt.edu/linearalgebra}
}
\date{}


\subject{Determinants}
% This is only inserted into the PDF information catalog. Can be left
% out. 

\begin{document}
\begin{frame}
  \titlepage
\end{frame}

% =============================================
% \begin{frame}{Reduced Echelon Form} 
% \end{frame}



% ..... Four.I.1,2 .....
\section{Properties of Determinants}
%..........
\begin{frame}{Nonsingular matrices}
\noindent An \( \nbyn{n} \) matrix \( T \) is nonsingular if and only if
each of these holds:%
\ExecuteMetaData[../det1.tex]{EquivalentOfNonsingular}
This chapter develops a formula to determine whether a
matrix is nonsingular.
\end{frame}




\begin{frame}
\ExecuteMetaData[../det1.tex]{DeterminantIntro}  
\end{frame}




\begin{frame}{A remark on how we will proceed}
The prior slide gives a formula for the $\nbyn{1}$, $\nbyn{2}$, and~$\nbyn{3}$
determinants. 
We will eventually give a formula for the general $\nbyn{n}$~case,
the permutation expansion.
However, this formula has a number of disadvantages, including that 
it is much too slow for practical computations when $n$ is of any
substantial size. 

Instead, we will define a
determinant function as one that satisfies some conditions. 
These conditions let us apply Gauss's Method, which we know to
be fast and easy.
(They conditions extrapolate from the $\nbyn{1}$, $\nbyn{2}$, 
and~$\nbyn{3}$cases; see the discussion in the book.) 

Proceeding by using a list of conditions has the downside that we must 
show that there is at most one function satisfying those conditions, and 
we must also show that such a function exists at all. 
So this development introduces some technicalities of theory.
But mastering them is well within our scope so this is the
best way to proceed.
\end{frame}




\begin{frame}{Definition of determinant}
\df[def:Det]
\ExecuteMetaData[../det1.tex]{df:Det}

\pause 
\re[rem:SwapRowsRedun] % \hspace*{-1em} 
\ExecuteMetaData[../det1.tex]{re:SwapRowsRedun}
\end{frame}




\begin{frame}{Consequences of the definition}
\lm[le:IdenRowsDetZero]
\ExecuteMetaData[../det1.tex]{lm:IdenRowsDetZero}

\pause 
\pf 
\ExecuteMetaData[../det1.tex]{pf:IdenRowsDetZero0}

\pause
\ExecuteMetaData[../det1.tex]{pf:IdenRowsDetZero1}
\end{frame}
\begin{frame}
\ExecuteMetaData[../det1.tex]{pf:IdenRowsDetZero2}

\pause
\ExecuteMetaData[../det1.tex]{pf:IdenRowsDetZero3}  
\end{frame}
\begin{frame}
\ExecuteMetaData[../det1.tex]{pf:IdenRowsDetZero4}
\qed
\end{frame}




\begin{frame}
We will prove later that there is a function satisfying the definition 
of determinant. 
For the moment we proceed without that assurance.

We can compute the determinant of a matrix using Gauss's Method

\ex  On this matrix we can perform the Gauss's Method steps of
$-2\rho_1+\rho_2$ and $-3\rho_1+\rho_3$.
Condition~(1) says that these row combination operations
leave the determinant unchanged.
\begin{equation*}
  \begin{vmat}
    1  &3  &-2 \\
    2  &0  &4  \\
    3  &-1 &5
  \end{vmat}
  =
  \begin{vmat}
    1  &3   &-2 \\
    0  &-6  &-8  \\
    0  &-10 &-11
  \end{vmat}
\end{equation*}
\pause
Again by condition~(1), the operation
$-(5/3)\rho_2+\rho_3$ does not change the determinant.
\begin{equation*}
  =
  \begin{vmat}
    1  &3   &-2 \\
    0  &-6  &-8  \\
    0  &0   &-7/3
  \end{vmat}
\end{equation*}
\pause
By the prior lemma we can now 
find the determinant by taking the product down the
diagonal.
\begin{equation*}
  =1\cdot(-6)\cdot(-7/3)=14
\end{equation*}
\end{frame}

\begin{frame}
\ex
To illustrate what happens with a row swap operation,
consider this matrix. 
The swap changes the determinant's sign.
\begin{equation*}
  \begin{vmat}
    0  &3  &1 \\
    1  &2  &0 \\
    1  &5  &2
  \end{vmat}
  =
  -\begin{vmat}
    1  &2  &0 \\
    0  &3  &1 \\
    1  &5  &2
  \end{vmat}
\end{equation*}
Finish by performing $-\rho_1+\rho_3$
\begin{equation*}
  =-\begin{vmat}
    1  &2  &0 \\
    0  &3  &1 \\
    0  &3  &2
  \end{vmat}
\end{equation*}
and $-\rho_2+\rho_3$
\begin{equation*}
  =-\begin{vmat}
    1  &2  &0 \\
    0  &3  &1 \\
    0  &0  &1
  \end{vmat}
\end{equation*}
and then multiplying down the diagonal.
The determinant of the original matrix is $-3$.
\end{frame}


\begin{frame}
\ex
Finally, to illustrate condition~(3) contrast these two.
\begin{equation*}
  \begin{vmat}
    5 &10 \\
    3 &4
  \end{vmat}
  \qquad
  \begin{vmat}
    1 &2 \\
    3 &4
  \end{vmat}
\end{equation*}
Condition~(3) gives
\begin{equation*}
  \begin{vmat}
    5 &10 \\
    3 &4
  \end{vmat}
  =5\cdot
  \begin{vmat}
    1 &2 \\
    3 &4
  \end{vmat}
\end{equation*}
and by performing $-3\rho_1+\rho_2$
and multiplying down the diagonal we get this.
\begin{equation*}
  =5\cdot
  \begin{vmat}
    1 &2 \\
    3 &4
  \end{vmat}
  =5\cdot
  \begin{vmat}
    1 &2 \\
    0 &-2
  \end{vmat}
  =5\cdot(-2)
  =-10
\end{equation*}
Thus here is the contrast.
\begin{equation*}
  \begin{vmat}
    5 &10 \\
    3 &4
  \end{vmat}
  =-10
  \qquad
  \begin{vmat}
    1 &2 \\
    3 &4
  \end{vmat}
  =-2
\end{equation*}
\end{frame}



\begin{frame}{The  determinant is unique}

Recall the process by which we are developing the determinant.
The definition gives four conditions that any determinant function must
satisfy.
The prior slides show how these conditions 
allow us to use Gauss's Method to produce a value.
That value has to be the output any function satisfying
the definition.


\lm[lm:DetFcnIsUnique]
\ExecuteMetaData[../det1.tex]{lm:DetFcnIsUnique}

\pause 
\pf 
\ExecuteMetaData[../det1.tex]{pf:DetFcnIsUnique}
\qed

\medskip
So if there is a function mapping $\matspace_{\nbyn{n}}$ to $\Re$ that
satisfies the four conditions of the definition then there is only one such
function.
\end{frame}
\begin{frame}{More process discussion}
How could there fail to be such a function?
\ExecuteMetaData[../det1.tex]{DifferentGaussMethodReductions}

\pause
That we get consistent results for these two
reductions on a single matrix does not ensure that all determinants
give well-defined values.
Our algorithm does not
plainly eliminate the possibility that there may be, say,
two Gauss's Method reductions of some $\nbyn{7}$~matrix that lead to different 
returned values.
\end{frame}
\begin{frame}
In particular, recall that the definition's condition~(2),
that row swaps change the sign of the determinant, is 
redundant.
Imagine that we did not notice the need for a sign change and had mistakenly
proposed a definition where row swaps leave the determinant unchanged.
Then the prior slide's pair of $\nbyn{2}$ calculations yield the
conflicting values of $-2$ and~$2$.
We must prove that our defintion does not lead to 
such a thing, 

\pause
To show that determinants are well-defined 
we will give an alternative way to compute
the value of a determinant, a formula that does not involve 
Gauss's Method.
We mentioned this above, it is the Permutation Expansion. 
It is less useful than Gauss's Method in practice since it 
is awkward and slow.
But it is useful for theory, and we need it now.
\end{frame}



% ..... Four.I.3 .....
\section{The Permutation Expansion}

\begin{frame}{The determinant function is not linear}
\ex
The determinant does not in general satisfy that 
$\det(k\cdot T)=k\cdot\det(T)$.
The second matrix here is twice the first
but the determinant does not double.
\begin{equation*}
  \begin{vmat}
    3  &-3  &9 \\
    1  &-1   &7 \\
    2  &4   &0
  \end{vmat}
  =-72
  \qquad
  \begin{vmat}
    6  &-6  &18 \\
    2  &-2   &14 \\
    4  &8   &0
  \end{vmat}
  =-576
\end{equation*}
Condition~(3) % of \nearbydefinition{def:Det}%
has the determinant scale one row at a time.   
\begin{align*}
  \begin{vmat}
    6  &-6  &18 \\
    2  &-2   &14 \\
    4  &8   &0
  \end{vmat}
  &=2\cdot
  \begin{vmat}
    3  &-3  &9 \\
    2  &-2   &14 \\
    4  &8   &0
  \end{vmat}           \\
  &=4\cdot
  \begin{vmat}
    3  &-3  &9 \\
    1  &-1   &7 \\
    4  &8   &0
  \end{vmat}           \\
  &=8\cdot
  \begin{vmat}
    3  &-3  &9 \\
    1  &-1   &7 \\
    2  &4   &0
  \end{vmat}         
\end{align*}
\end{frame}
\begin{frame}
So determinants are not linear:~with scalar multiplication,
the scalars come out one row at a time.
What happens with addition?

Consider condition~(3) applied to the case   
% \begin{equation*}
%   \det (\vec{\rho}_1,\dots,k\vec{\rho}_i,\dots,\vec{\rho}_n)
%        = k\cdot \det (\vec{\rho}_1,\dots,\vec{\rho}_i,\dots,\vec{\rho}_n)
% \end{equation*}
$k=2$.
\begin{equation*}
  \det (\vec{\rho}_1,\dots,2\vec{\rho}_i,\dots,\vec{\rho}_n)
       = 2\cdot \det (\vec{\rho}_1,\dots,\vec{\rho}_i,\dots,\vec{\rho}_n)
\end{equation*}
Rewrite it as addition. 
\begin{multline*}
  \det (\vec{\rho}_1,\dots,\vec{\rho}_i+\vec{\rho}_i,\dots,\vec{\rho}_n) \\
       = \det (\vec{\rho}_1,\dots,\vec{\rho}_i,\dots,\vec{\rho}_n)
         +\det (\vec{\rho}_1,\dots,\vec{\rho}_i,\dots,\vec{\rho}_n)
\end{multline*}
Of course this extends to $k=3$, etc.

This hints that besides bringing out scalars one row at a time,
determinants also break along a plus sign one row at a time.
\end{frame}


%..........
\begin{frame}{Multilinear}
\df[def:multilinear]
\ExecuteMetaData[../det1.tex]{df:Multilinear}


\lm[lem:DetsMultilinear]
\ExecuteMetaData[../det1.tex]{lm:DetsMultilinear}

\pause
\pf
\ExecuteMetaData[../det1.tex]{pf:DetsMultilinear0}

\pause
\ExecuteMetaData[../det1.tex]{pf:DetsMultilinear1}
\end{frame}
\begin{frame}
\ExecuteMetaData[../det1.tex]{pf:DetsMultilinear2}
\end{frame}
\begin{frame}
\ExecuteMetaData[../det1.tex]{pf:DetsMultilinear3}
\qed
\end{frame}



\begin{frame}
Multilinearity breaks a determinant into a sum of 
simple ones.

\ex
We can expand this determinant
\begin{equation*}
  \begin{vmat}
    1 &2 \\
    3 &4
  \end{vmat}
\end{equation*}
along the first row
\begin{equation*}
  =\begin{vmat}
    1 &0 \\
    3 &4
  \end{vmat}
  +\begin{vmat}
    0 &2 \\
    3 &4
  \end{vmat}
\end{equation*}
and then expand both of those on second row.
\begin{equation*}
  =\begin{vmat}
    1 &0 \\
    3 &0
  \end{vmat}
  +\begin{vmat}
    1 &0 \\
    0 &4
  \end{vmat}
  +\begin{vmat}
    0 &2 \\
    3 &0
  \end{vmat}
  +\begin{vmat}
    0 &2 \\
    0 &4
  \end{vmat}
\end{equation*}
Each matrix is simple in that  
of its rows are all zeroes except
for a single entry from the starting matrix.

\pause
Of these four, the first and last are~$0$ 
because the matrices are
nonsingular, since they have a second row that is a multiple of 
the first.
We are left with two determinants, where 
in each the matrix is all zeros except for 
one entry from the starting matrix in each row and each column.
We'll show our strategy for evaluating these determinants below.
\end{frame}




\begin{frame}
\ex
Similarly we can use multilinearity to expand this determinant. 
\begin{align*}
  \begin{vmat}
    1 &2 &3 \\
    4 &5 &6 \\
    7 &8 &9
  \end{vmat}
  &=\begin{vmat}
    1 &0 &0 \\
    4 &0 &0 \\
    7 &0 &0
  \end{vmat}
  +\begin{vmat}
    1 &0 &0 \\
    4 &0 &0 \\
    0 &8 &0
  \end{vmat}
  +\begin{vmat}
    1 &0 &0 \\
    4 &0 &0 \\
    0 &0 &9
  \end{vmat}  \\
  &\quad+\begin{vmat}
    1 &0 &0 \\
    0 &5 &0 \\
    7 &0 &0
  \end{vmat}
  +\begin{vmat}
    1 &0 &0 \\
    0 &5 &0 \\
    0 &8 &0
  \end{vmat}
  +\begin{vmat}
    1 &0 &0 \\
    0 &5 &0 \\
    0 &0 &9
  \end{vmat}           \\
  &\quad+\begin{vmat}
    1 &0 &0 \\
    0 &0 &6 \\
    7 &0 &0
  \end{vmat}
  +\begin{vmat}
    1 &0 &0 \\
    0 &0 &6 \\
    0 &8 &0
  \end{vmat}
  +\begin{vmat}
    1 &0 &0 \\
    0 &0 &6 \\
    0 &0 &9
  \end{vmat}       \\
  &\quad+\begin{vmat}
    0 &2 &0 \\
    4 &0 &0 \\
    7 &0 &0
  \end{vmat}
  +\qquad\cdots\qquad+
  \begin{vmat}
    0 &0 &3 \\
    0 &0 &6 \\
    0 &0 &9
  \end{vmat}
\end{align*}
In each of the $3^3=27$~determinants on the right the matrix is all zeros but
for a single entry from the starting matrix in each row. 
\end{frame}

\begin{frame}
\begin{equation*}
  \begin{vmat}
    1 &2 &3 \\
    4 &5 &6 \\
    7 &8 &9
  \end{vmat}
  =\begin{vmat}
    1 &0 &0 \\
    4 &0 &0 \\
    7 &0 &0
  \end{vmat}
  +\begin{vmat}
    1 &0 &0 \\
    4 &0 &0 \\
    0 &8 &0
  \end{vmat}
  +\cdots+
  \begin{vmat}
    0 &0 &3 \\
    0 &0 &6 \\
    0 &8 &0
  \end{vmat}
  +\begin{vmat}
    0 &0 &3 \\
    0 &0 &6 \\
    0 &0 &9
  \end{vmat}
\end{equation*}
For any of these, if two of the matrix rows have their original 
matrix entries in the same column then the determinant is~$0$
since then one matrix row is a multiple of the other.

\pause
We've reduced to a sum of determinants, 
where each matrix is all $0$'s but
for a single entry from the original in each row and column.
There are $3\cdot 2\cdot 1=6$ of these. 
\end{frame}
\begin{frame}
\vspace*{-3ex}
\begin{align*}
  \begin{vmat}
    1 &2 &3 \\
    4 &5 &6 \\
    7 &8 &9
  \end{vmat}
  &=\begin{vmat}
    1 &0 &0 \\
    0 &5 &0 \\
    0 &0 &9
  \end{vmat}
  +\begin{vmat}
    1 &0 &0 \\
    0 &0 &6 \\
    0 &8 &0
  \end{vmat}            \\
  &\quad+\begin{vmat}
    0 &2 &0 \\
    4 &0 &0 \\
    0 &0 &9
  \end{vmat}
  +\begin{vmat}
    0 &2 &0 \\
    0 &0 &6 \\
    7 &0 &0
  \end{vmat}         \\
  &\quad+\begin{vmat}
    0 &0 &3 \\
    4 &0 &0 \\
    0 &8 &0
  \end{vmat}
  +\begin{vmat}
    0 &0 &3 \\
    0 &5 &0 \\
    7 &0 &0
  \end{vmat}            \\
  &=45\cdot\begin{vmat}
    1 &0 &0 \\
    0 &1 &0 \\
    0 &0 &1
  \end{vmat}
  +48\cdot\begin{vmat}
    1 &0 &0 \\
    0 &0 &1 \\
    0 &1 &0
  \end{vmat}            \\
  &\quad+72\cdot\begin{vmat}
    0 &1 &0 \\
    1 &0 &0 \\
    0 &0 &1
  \end{vmat}
  +84\cdot\begin{vmat}
    0 &1 &0 \\
    0 &0 &1 \\
    1 &0 &0
  \end{vmat}         \\
  &\quad+96\cdot\begin{vmat}
    0 &0 &1 \\
    1 &0 &0 \\
    0 &1 &0
  \end{vmat}
  +105\cdot\begin{vmat}
    0 &0 &1 \\
    0 &1 &0 \\
    1 &0 &0
  \end{vmat}
\end{align*}
\end{frame}
\begin{frame}
\noindent
After bringing out each entry from the original matrix, we are left with 
matrices that are all $0$'s except for a single~$1$ in each row and column.

So, the only one thing remains 
to be done in our process of justifying the definition 
of determinant by finding a way to express 
determinants without using Gauss's Method:~give a formula for
the determinant of such matrices (not involving Gauss's Method).
\end{frame}



\begin{frame}{Permutation matrices}
\ExecuteMetaData[../det1.tex]{NotationForPermutationMatrices}

\pause
\df[df:permutation]
\ExecuteMetaData[../det1.tex]{df:permutation}

So, in a permutation each number 
$1$, \ldots, $n$ is the output associated with one and only one input.
We sometimes denote a permutation as the sequence 
$\phi=\sequence{\phi(1),\phi(2),\ldots,\phi(n)}$.

\ex[ex:AllTwoThreePerms]
These are the $2$-permutations.
\begin{center}
  \begin{tabular}{rcc}
    $\phi_1$:  &$1\mapsto 1$  &$2\mapsto 2$  \\
    $\phi_2$:  &$1\mapsto 2$  &$2\mapsto 1$      
  \end{tabular}
\end{center}
The sequence notation is shorter:
\( \phi_1=\sequence{1,2} \) and \( \phi_2=\sequence{2,1} \).
% \ExecuteMetaData[../det1.tex]{ex:AllTwoPerms}
\ex[ex:AllThreePerms]
\ExecuteMetaData[../det1.tex]{ex:AllThreePerms}
\end{frame}
\begin{frame}
\ExecuteMetaData[../det1.tex]{AssociatePermutationWithPermutationMatrix}

\ex
Associated with the $4$-permutation $\psi=\sequence{2,4,3,1}$ is the
matrix whose rows are the matching $\iota$'s.
\begin{equation*}
  P_{\psi}
  =
  \begin{mat}
    \iota_2 \\
    \iota_4 \\
    \iota_3 \\
    \iota_1
  \end{mat}
  =
  \begin{mat}
    0 &1 &0 &0 \\
    0 &0 &0 &1 \\
    0 &0 &1 &0 \\
    1 &0 &0 &0
  \end{mat}
\end{equation*}
\end{frame}




\begin{frame}{Permutation expansion}
\df[df:PermutationExpansion]
\ExecuteMetaData[../det1.tex]{df:PermutationExpansion}

\pause
\medskip
\ExecuteMetaData[../det1.tex]{SummationForPermutationExpansion}
\end{frame}
\begin{frame}
\ex
Recall that there are two $2$-permutations
\( \phi_1=\sequence{1,2} \) and \( \phi_2=\sequence{2,1} \).
% So for the $\nbyn{2}$ case, the sum over all permutations has two terms.
These are the associated permutation matrices
\begin{equation*}
  P_{\phi_1}=
  \begin{mat}
    1 &0 \\
    0 &1
  \end{mat}
  \qquad
  P_{\phi_2}=
  \begin{mat}
    0 &1 \\
    1 &0
  \end{mat}
\end{equation*}
\pause
giving this expansion.
\begin{align*}
  \begin{vmat}
    t_{1,1}  &t_{1,2} \\
    t_{2,1}  &t_{2,2}
  \end{vmat}
  &=
  t_{1,1}t_{2,2}\cdot
  \begin{vmat}
    1  &0 \\
    0  &1
  \end{vmat}               
  +
  t_{1,2}t_{2,1}\cdot
  \begin{vmat}
    0  &1 \\
    1  &0
  \end{vmat}               \\
  &=
  t_{1,1}t_{2,2}\cdot 1
  +
  t_{1,2}t_{2,1}\cdot (-1)
\end{align*}
(From prior work we know that the determinant $\deter{P_{\phi_2}}$ 
equals~$-1$ because we can bring that to 
the identity matrix with one row swap.)
\pause
Renaming the matrix entries gives the familiar $\nbyn{2}$ formula.
\begin{equation*}
  \begin{vmat}
    a  &b  \\
    c  &d
  \end{vmat}
  =ad-bc
\end{equation*}
\end{frame}




\begin{frame}
The next subsection does the proof of 
these two theorems.

\th[th:DetsExist]
\ExecuteMetaData[../det1.tex]{th:DetsExist}

\th[th:DeterminantOfAMatrixEqualsDeterminantOfTranspose]
\ExecuteMetaData[../det1.tex]{th:DeterminantOfAMatrixEqualsDeterminantOfTranspose}

\pause
\co[cor:ColSwapChgSign]
\ExecuteMetaData[../det1.tex]{co:ColSwapChgSign}
\pause
\pf
\ExecuteMetaData[../det1.tex]{pf:ColSwapChgSign}
\qed
\end{frame}




% ..... Four.I.4 .....
\section{Determinants Exist}
%..........
\begin{frame}{Inversion}
\df[df:Inversion]
\ExecuteMetaData[../det1.tex]{df:Inversion}
\pause
\ex The permutation $\phi=\sequence{3,2,1}$ has three inversions:
$3$ is before $2$, $3$ is before $1$, and 
$2$ is before $1$.
\end{frame}
\begin{frame}
\ex
Here there are two inversions:
\begin{equation*}
  \begin{mat}
    0 &1 &0 &0 \\
    1 &0 &0 &0 \\
    0 &0 &0 &1 \\
    0 &0 &1 &0
  \end{mat}
\end{equation*}
row one is inverted with respect to row~two and row~three is inverted with 
respect to row~four.
\end{frame}




%..........
\begin{frame}
\lm[le:SwapsChangeSgn]
\ExecuteMetaData[../det1.tex]{lm:SwapsChangeSgn}

\pause
\pf
\ExecuteMetaData[../det1.tex]{pf:SwapsChangeSgn0}
\end{frame}
\begin{frame}
\ExecuteMetaData[../det1.tex]{pf:SwapsChangeSgn1}
\end{frame}
\begin{frame}
\noindent\ExecuteMetaData[../det1.tex]{pf:SwapsChangeSgn2}
\qed
\end{frame}




%..........
\begin{frame}{Signum}
\df[df:Signum]
\ExecuteMetaData[../det1.tex]{df:Signum}

\pause
\ex The permutation
$\phi=\sequence{3,2,1}$
associated with this matrix 
\begin{equation*}
  P_{\phi}=
  \begin{mat}
    0 &0 &1 \\
    0 &1 &0 \\
    1 &0 &0
  \end{mat}
\end{equation*}
has three inversions
$3$ is before $2$, $3$ is before $1$, and 
$2$ is before $1$.
So the signum is $\sgn(\phi)=-1$.

\pause
\ex
The permutation $\psi=\sequence{3,2,4,1}$
has four inversions: $3$ is before $2$ and~$1$,
$2$ is before~$1$, and $4$ is before~$1$.
So $\sgn(\psi)=+1$.
\end{frame}




%..........
\begin{frame}
\co[cor:ParityInversEqParitySwaps]
\ExecuteMetaData[../det1.tex]{co:ParityInversEqParitySwaps}

\pause
\pf
\ExecuteMetaData[../det1.tex]{pf:ParityInversEqParitySwaps}
\qed
\end{frame}




%..........
\begin{frame}{Determinants exist}
Recall the process we are going through in the validation of the definition 
of determinant.
We want a formula for the determinant that gives an
obviously well-defined value.
(This is in contrast to calculating determinants using Gauss's Method,
which can be done in more than one way.)
Here is that formula.

\ExecuteMetaData[../det1.tex]{DefiningDFunction}
\end{frame}
\begin{frame}
\lm[lm:DeterminantsExist]
\ExecuteMetaData[../det1.tex]{lm:DeterminantsExist}

\pf
\ExecuteMetaData[../det1.tex]{pf:DeterminantsExist0}

\pause
\ExecuteMetaData[../det1.tex]{pf:DeterminantsExist1}
% \end{frame}
% \begin{frame}

\pause
\ExecuteMetaData[../det1.tex]{pf:DeterminantsExist2}
\end{frame}
\begin{frame}
\ExecuteMetaData[../det1.tex]{pf:DeterminantsExist3}
\end{frame}
\begin{frame}
\noindent\ExecuteMetaData[../det1.tex]{pf:DeterminantsExist4}
\end{frame}
\begin{frame}
\ExecuteMetaData[../det1.tex]{pf:DeterminantsExist5}
\end{frame}
\begin{frame}
\ExecuteMetaData[../det1.tex]{pf:DeterminantsExist6}
\end{frame}
\begin{frame}
\ExecuteMetaData[../det1.tex]{pf:DeterminantsExist7}
\qed
\end{frame}




%..........
\begin{frame}{The determinant of the transpose}
\th[th:DetMatrixEqualsDetTrans]
\ExecuteMetaData[../det1.tex]{th:DetMatrixEqualsDetTrans}

\pf
\ExecuteMetaData[../det1.tex]{pf:DetMatrixEqualsDetTrans0}
\end{frame}
\begin{frame}
\ExecuteMetaData[../det1.tex]{pf:DetMatrixEqualsDetTrans1} 
\end{frame}
\begin{frame}
\ExecuteMetaData[../det1.tex]{pf:DetMatrixEqualsDetTrans2}
\qed

\pause
\ex
We know the formula for $\nbyn{2}$~matrices.
\begin{equation*}
  \begin{vmat}
    a  &b  \\
    c  &d
  \end{vmat}
  =ad-bc
  \qquad
  \begin{vmat}
    a  &c  \\
    b  &d
  \end{vmat}
  =ad-cb
\end{equation*}
\end{frame}



% % ..... Four.I.2 .....
% \section{}
% %..........
% \begin{frame}
% \end{frame}




%...........................
% \begin{frame}
% \ExecuteMetaData[../gr3.tex]{GaussJordanReduction}
% \df[def:RedEchForm]
% 
% \end{frame}
\end{document}
